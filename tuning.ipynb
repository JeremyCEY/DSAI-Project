{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import basic libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import essential models and functions from sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>bed_time</th>\n",
       "      <th>wakeup_time</th>\n",
       "      <th>sleep_duration</th>\n",
       "      <th>sleep_efficiency</th>\n",
       "      <th>rem_sleep_percentage</th>\n",
       "      <th>deep_sleep_percentage</th>\n",
       "      <th>light_sleep_percentage</th>\n",
       "      <th>...</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>exercise_frequency</th>\n",
       "      <th>exercise_frequency_filled</th>\n",
       "      <th>bed_time_edited</th>\n",
       "      <th>bed_time_encoded</th>\n",
       "      <th>wakeup_time_edited</th>\n",
       "      <th>wakeup_time_encoded</th>\n",
       "      <th>smoking</th>\n",
       "      <th>gender_type</th>\n",
       "      <th>sleep_quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>Female</td>\n",
       "      <td>01:00</td>\n",
       "      <td>07:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.88</td>\n",
       "      <td>18</td>\n",
       "      <td>70</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.038628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>69</td>\n",
       "      <td>Male</td>\n",
       "      <td>02:00</td>\n",
       "      <td>09:00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>19</td>\n",
       "      <td>28</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.705723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>Female</td>\n",
       "      <td>21:30</td>\n",
       "      <td>05:30</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.89</td>\n",
       "      <td>20</td>\n",
       "      <td>70</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21</td>\n",
       "      <td>21.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.876008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>Female</td>\n",
       "      <td>02:30</td>\n",
       "      <td>08:30</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.51</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>52</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.028781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>57</td>\n",
       "      <td>Male</td>\n",
       "      <td>01:00</td>\n",
       "      <td>09:00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>27</td>\n",
       "      <td>55</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.192627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  age  gender bed_time wakeup_time  sleep_duration  sleep_efficiency  \\\n",
       "0   1   65  Female    01:00       07:00             6.0              0.88   \n",
       "1   2   69    Male    02:00       09:00             7.0              0.66   \n",
       "2   3   40  Female    21:30       05:30             8.0              0.89   \n",
       "3   4   40  Female    02:30       08:30             6.0              0.51   \n",
       "4   5   57    Male    01:00       09:00             8.0              0.76   \n",
       "\n",
       "   rem_sleep_percentage  deep_sleep_percentage  light_sleep_percentage  ...  \\\n",
       "0                    18                     70                      12  ...   \n",
       "1                    19                     28                      53  ...   \n",
       "2                    20                     70                      10  ...   \n",
       "3                    23                     25                      52  ...   \n",
       "4                    27                     55                      18  ...   \n",
       "\n",
       "   smoking_status  exercise_frequency  exercise_frequency_filled  \\\n",
       "0             Yes                 3.0                        3.0   \n",
       "1             Yes                 3.0                        3.0   \n",
       "2              No                 3.0                        3.0   \n",
       "3             Yes                 1.0                        1.0   \n",
       "4              No                 3.0                        3.0   \n",
       "\n",
       "   bed_time_edited  bed_time_encoded  wakeup_time_edited wakeup_time_encoded  \\\n",
       "0                1               1.0                   7                 7.0   \n",
       "1                2               2.0                   9                 9.0   \n",
       "2               21              21.0                   5                 5.0   \n",
       "3                2               2.0                   8                 8.0   \n",
       "4                1               1.0                   9                 9.0   \n",
       "\n",
       "   smoking  gender_type  sleep_quality  \n",
       "0        1            0      -1.038628  \n",
       "1        1            1       1.705723  \n",
       "2        0            0      -0.876008  \n",
       "3        1            0       2.028781  \n",
       "4        0            1       0.192627  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('dataset/pca-sleep-efficiency.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[['age','gender_type','wakeup_time_encoded','bed_time_encoded','sleep_duration', 'exercise_frequency_filled', 'caffeine_consumption_filled', 'alcohol_consumption_filled', 'smoking']]\n",
    "y = dataset['sleep_quality']\n",
    "\n",
    "# Perform first split\n",
    "X_train_temp, X_test, y_train_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=100)\n",
    "\n",
    "# Perform the second split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_temp, y_train_temp, test_size=0.25, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.37288136, 0.        , 0.55555556, 0.04347826, 0.4       ,\n",
       "        0.        , 0.125     , 0.2       , 0.        ],\n",
       "       [0.3220339 , 0.        , 0.55555556, 0.        , 0.6       ,\n",
       "        0.2       , 0.125     , 0.8       , 0.        ],\n",
       "       [0.52542373, 0.        , 0.22222222, 0.91304348, 0.5       ,\n",
       "        0.6       , 0.375     , 0.4       , 1.        ],\n",
       "       [0.33898305, 0.        , 0.22222222, 0.        , 0.        ,\n",
       "        0.4       , 0.375     , 0.        , 1.        ],\n",
       "       [0.15254237, 1.        , 0.66666667, 0.04347826, 0.5       ,\n",
       "        0.6       , 0.        , 0.        , 0.        ],\n",
       "       [0.25423729, 0.        , 0.22222222, 0.95652174, 0.4       ,\n",
       "        0.        , 0.125     , 0.        , 0.        ],\n",
       "       [0.66101695, 0.        , 0.22222222, 0.95652174, 0.4       ,\n",
       "        0.8       , 0.        , 0.4       , 0.        ],\n",
       "       [0.54237288, 1.        , 0.22222222, 0.95652174, 0.4       ,\n",
       "        0.6       , 0.        , 0.4       , 1.        ],\n",
       "       [0.59322034, 1.        , 1.        , 0.08695652, 1.        ,\n",
       "        0.6       , 0.        , 0.        , 0.        ],\n",
       "       [0.27118644, 1.        , 0.33333333, 0.95652174, 0.6       ,\n",
       "        0.6       , 0.125     , 0.        , 0.        ],\n",
       "       [0.33898305, 0.        , 0.33333333, 0.95652174, 0.6       ,\n",
       "        0.4       , 0.375     , 0.        , 0.        ],\n",
       "       [0.86440678, 1.        , 0.66666667, 0.04347826, 0.6       ,\n",
       "        0.6       , 0.        , 0.6       , 0.        ],\n",
       "       [0.27118644, 1.        , 0.11111111, 0.91304348, 0.4       ,\n",
       "        0.6       , 0.25      , 0.2347032 , 0.        ],\n",
       "       [0.77966102, 1.        , 0.44444444, 1.        , 0.6       ,\n",
       "        0.6       , 0.        , 0.        , 1.        ],\n",
       "       [0.49152542, 0.        , 0.11111111, 0.95652174, 0.2       ,\n",
       "        0.8       , 0.        , 0.        , 0.        ],\n",
       "       [0.33898305, 0.        , 0.44444444, 0.        , 0.5       ,\n",
       "        0.4       , 0.375     , 0.2       , 1.        ],\n",
       "       [0.79661017, 1.        , 0.44444444, 0.08695652, 0.        ,\n",
       "        0.6       , 0.        , 0.        , 1.        ],\n",
       "       [0.15254237, 0.        , 0.77777778, 0.04347826, 0.8       ,\n",
       "        0.        , 0.25      , 0.        , 0.        ],\n",
       "       [0.30508475, 0.        , 0.33333333, 0.95652174, 0.6       ,\n",
       "        1.        , 0.125     , 1.        , 1.        ],\n",
       "       [0.23728814, 0.        , 0.66666667, 0.08695652, 0.4       ,\n",
       "        0.2       , 0.25      , 1.        , 1.        ],\n",
       "       [0.66101695, 0.        , 0.22222222, 0.91304348, 0.5       ,\n",
       "        0.8       , 0.        , 0.        , 0.        ],\n",
       "       [0.54237288, 1.        , 0.77777778, 0.08695652, 0.5       ,\n",
       "        0.6       , 0.        , 0.        , 0.        ],\n",
       "       [0.28813559, 1.        , 0.22222222, 0.95652174, 0.4       ,\n",
       "        0.6       , 0.        , 0.        , 0.        ],\n",
       "       [0.40677966, 0.        , 0.77777778, 0.08695652, 0.5       ,\n",
       "        0.2       , 0.25      , 0.        , 0.        ],\n",
       "       [0.91525424, 0.        , 0.77777778, 0.08695652, 0.6       ,\n",
       "        0.2       , 0.25      , 0.        , 0.        ],\n",
       "       [0.71186441, 1.        , 0.33333333, 0.95652174, 0.6       ,\n",
       "        0.8       , 0.        , 0.        , 0.        ],\n",
       "       [0.50847458, 1.        , 0.66666667, 0.08695652, 0.4       ,\n",
       "        0.4       , 0.11826698, 0.        , 1.        ],\n",
       "       [0.25423729, 1.        , 0.55555556, 0.        , 0.6       ,\n",
       "        0.4       , 0.        , 0.2347032 , 0.        ],\n",
       "       [0.66101695, 0.        , 0.33333333, 0.95652174, 0.6       ,\n",
       "        0.8       , 0.        , 0.        , 0.        ],\n",
       "       [0.3559322 , 0.        , 0.33333333, 1.        , 0.5       ,\n",
       "        0.2       , 0.25      , 0.4       , 1.        ],\n",
       "       [0.40677966, 0.        , 0.66666667, 1.        , 1.        ,\n",
       "        0.        , 0.125     , 0.2       , 0.        ],\n",
       "       [0.33898305, 0.        , 0.11111111, 0.91304348, 0.4       ,\n",
       "        0.4       , 0.        , 0.        , 0.        ],\n",
       "       [0.94915254, 1.        , 0.22222222, 0.        , 0.        ,\n",
       "        0.2       , 0.        , 0.        , 0.        ],\n",
       "       [0.16949153, 0.        , 0.44444444, 0.        , 0.5       ,\n",
       "        0.2       , 0.125     , 0.        , 0.        ],\n",
       "       [0.61016949, 1.        , 0.44444444, 0.08695652, 0.        ,\n",
       "        0.4       , 0.        , 0.        , 1.        ],\n",
       "       [0.71186441, 1.        , 0.66666667, 0.        , 0.7       ,\n",
       "        0.6       , 0.25      , 0.        , 1.        ],\n",
       "       [0.50847458, 0.        , 0.44444444, 1.        , 0.6       ,\n",
       "        0.8       , 0.25      , 0.4       , 0.        ],\n",
       "       [0.74576271, 1.        , 0.77777778, 0.        , 1.        ,\n",
       "        0.6       , 0.25      , 0.        , 1.        ],\n",
       "       [0.74576271, 1.        , 0.66666667, 0.04347826, 0.6       ,\n",
       "        0.2       , 0.125     , 0.        , 1.        ],\n",
       "       [0.30508475, 0.        , 0.33333333, 0.95652174, 0.6       ,\n",
       "        0.4       , 0.375     , 0.        , 1.        ],\n",
       "       [0.28813559, 0.        , 0.44444444, 0.        , 0.5       ,\n",
       "        0.2       , 0.25      , 0.4       , 1.        ],\n",
       "       [0.6779661 , 0.        , 0.22222222, 0.95652174, 0.4       ,\n",
       "        1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.50847458, 1.        , 0.44444444, 0.95652174, 0.8       ,\n",
       "        0.6       , 0.        , 0.        , 1.        ],\n",
       "       [0.52542373, 1.        , 0.11111111, 0.91304348, 0.5       ,\n",
       "        0.6       , 0.        , 0.        , 0.        ],\n",
       "       [0.94915254, 0.        , 0.66666667, 0.08695652, 0.4       ,\n",
       "        0.        , 0.25      , 0.        , 1.        ],\n",
       "       [0.76271186, 1.        , 0.66666667, 0.04347826, 0.6       ,\n",
       "        0.6       , 0.        , 0.6       , 0.        ],\n",
       "       [0.57627119, 1.        , 0.22222222, 0.95652174, 0.4       ,\n",
       "        0.6       , 0.        , 0.        , 0.        ],\n",
       "       [0.22033898, 1.        , 0.33333333, 1.        , 0.4       ,\n",
       "        0.8       , 0.375     , 0.2       , 0.        ],\n",
       "       [0.42372881, 0.        , 0.33333333, 1.        , 0.4       ,\n",
       "        0.        , 0.125     , 0.2       , 0.        ],\n",
       "       [0.59322034, 0.        , 0.44444444, 0.04347826, 0.2       ,\n",
       "        0.2       , 0.11826698, 0.        , 0.        ],\n",
       "       [0.59322034, 0.        , 0.22222222, 1.        , 0.2       ,\n",
       "        0.        , 0.125     , 1.        , 0.        ],\n",
       "       [0.20338983, 1.        , 0.66666667, 0.        , 0.7       ,\n",
       "        0.2       , 0.25      , 0.        , 1.        ],\n",
       "       [0.45762712, 0.        , 0.44444444, 1.        , 0.6       ,\n",
       "        0.8       , 0.25      , 0.4       , 0.        ],\n",
       "       [0.52542373, 0.        , 0.33333333, 0.95652174, 0.6       ,\n",
       "        0.6       , 0.        , 0.        , 0.        ],\n",
       "       [0.38983051, 0.        , 0.33333333, 0.04347826, 0.        ,\n",
       "        0.        , 0.125     , 0.2       , 0.        ],\n",
       "       [0.47457627, 1.        , 0.44444444, 0.95652174, 0.8       ,\n",
       "        0.6       , 0.        , 0.        , 0.        ],\n",
       "       [0.38983051, 0.        , 0.        , 0.91304348, 0.2       ,\n",
       "        0.        , 0.125     , 0.2       , 0.        ],\n",
       "       [0.79661017, 1.        , 0.66666667, 0.        , 0.7       ,\n",
       "        0.2       , 0.        , 0.        , 1.        ],\n",
       "       [0.57627119, 0.        , 0.66666667, 0.        , 0.8       ,\n",
       "        0.        , 0.125     , 0.2       , 0.        ],\n",
       "       [0.37288136, 0.        , 0.33333333, 0.95652174, 0.5       ,\n",
       "        0.2       , 0.25      , 0.        , 0.        ],\n",
       "       [0.25423729, 1.        , 0.44444444, 0.        , 0.5       ,\n",
       "        0.        , 0.        , 0.4       , 1.        ],\n",
       "       [0.30508475, 0.        , 0.22222222, 0.95652174, 0.5       ,\n",
       "        1.        , 0.125     , 0.        , 0.        ],\n",
       "       [0.38983051, 0.        , 0.88888889, 0.08695652, 0.8       ,\n",
       "        0.        , 0.125     , 0.        , 0.        ],\n",
       "       [0.49152542, 0.        , 0.33333333, 0.        , 0.2       ,\n",
       "        0.2       , 0.25      , 0.        , 1.        ],\n",
       "       [0.72881356, 1.        , 0.33333333, 0.95652174, 0.5       ,\n",
       "        0.8       , 0.        , 0.        , 0.        ],\n",
       "       [0.38983051, 1.        , 0.66666667, 0.04347826, 0.5       ,\n",
       "        0.2       , 0.25      , 0.        , 0.        ],\n",
       "       [0.44067797, 0.        , 0.55555556, 0.        , 0.6       ,\n",
       "        0.        , 0.125     , 0.2       , 1.        ],\n",
       "       [0.71186441, 1.        , 0.11111111, 0.95652174, 0.2       ,\n",
       "        0.8       , 0.        , 0.        , 0.        ],\n",
       "       [0.47457627, 1.        , 0.22222222, 0.91304348, 0.6       ,\n",
       "        0.6       , 0.        , 0.        , 0.        ],\n",
       "       [0.66101695, 0.        , 0.11111111, 0.91304348, 0.5       ,\n",
       "        0.8       , 0.125     , 0.        , 0.        ],\n",
       "       [0.55932203, 1.        , 0.11111111, 0.91304348, 0.5       ,\n",
       "        0.6       , 1.        , 0.        , 0.        ],\n",
       "       [0.52542373, 0.        , 0.44444444, 0.        , 0.5       ,\n",
       "        0.2       , 0.25      , 0.6       , 1.        ],\n",
       "       [0.15254237, 1.        , 0.55555556, 0.        , 0.6       ,\n",
       "        0.        , 0.125     , 0.        , 0.        ],\n",
       "       [0.30508475, 0.        , 0.55555556, 0.04347826, 0.4       ,\n",
       "        0.2       , 0.11826698, 0.8       , 0.        ],\n",
       "       [0.23728814, 1.        , 0.33333333, 0.91304348, 0.8       ,\n",
       "        0.6       , 0.        , 0.        , 0.        ],\n",
       "       [0.55932203, 1.        , 0.66666667, 0.08695652, 0.4       ,\n",
       "        0.4       , 0.        , 0.        , 1.        ],\n",
       "       [0.30508475, 0.        , 0.        , 0.91304348, 0.2       ,\n",
       "        0.2       , 0.25      , 0.        , 1.        ],\n",
       "       [0.52542373, 0.        , 0.33333333, 1.        , 0.4       ,\n",
       "        0.6       , 0.        , 0.        , 0.        ],\n",
       "       [0.47457627, 0.        , 0.44444444, 0.        , 0.4       ,\n",
       "        0.35829596, 0.125     , 0.2       , 1.        ],\n",
       "       [0.54237288, 1.        , 0.33333333, 0.95652174, 0.6       ,\n",
       "        0.6       , 0.        , 0.        , 1.        ],\n",
       "       [0.77966102, 0.        , 0.55555556, 0.04347826, 0.4       ,\n",
       "        0.2       , 0.11826698, 0.        , 0.        ],\n",
       "       [1.01694915, 1.        , 0.66666667, 0.08695652, 0.4       ,\n",
       "        0.6       , 0.        , 0.6       , 1.        ],\n",
       "       [0.86440678, 1.        , 0.33333333, 1.        , 0.4       ,\n",
       "        0.6       , 0.        , 0.4       , 1.        ],\n",
       "       [0.72881356, 1.        , 0.44444444, 0.        , 0.4       ,\n",
       "        0.2       , 0.11826698, 0.6       , 1.        ],\n",
       "       [0.38983051, 1.        , 0.77777778, 0.08695652, 0.5       ,\n",
       "        0.2       , 0.25      , 0.8       , 0.        ],\n",
       "       [0.40677966, 0.        , 0.11111111, 0.91304348, 0.5       ,\n",
       "        0.2       , 0.25      , 0.6       , 0.        ],\n",
       "       [0.72881356, 1.        , 0.44444444, 0.        , 0.4       ,\n",
       "        0.6       , 0.25      , 0.        , 1.        ],\n",
       "       [0.33898305, 0.        , 0.33333333, 0.95652174, 0.6       ,\n",
       "        1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.77966102, 1.        , 0.55555556, 0.        , 0.6       ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.74576271, 1.        , 0.11111111, 0.91304348, 0.4       ,\n",
       "        0.4       , 0.375     , 0.        , 0.        ],\n",
       "       [0.74576271, 1.        , 0.33333333, 1.        , 0.5       ,\n",
       "        0.4       , 0.125     , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the scaler with object range of 0-1\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform using the training data\n",
    "scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the validation and test features\n",
    "scaler.transform(X_valid)\n",
    "scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of the columns to drop\n",
    "cols_to_drop = ['gender_type', 'wakeup_time_encoded', 'sleep_duration','caffeine_consumption_filled','smoking']\n",
    "\n",
    "# Drop these columns from training, validation and test data\n",
    "X_train_temp.drop(columns=cols_to_drop,inplace=True)\n",
    "X_train.drop(columns=cols_to_drop,inplace=True)\n",
    "X_valid.drop(columns=cols_to_drop,inplace=True)\n",
    "X_test.drop(columns=cols_to_drop,inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000], 'max_depth': [3, 4, 5, 6, 7, 8, 9, 10], 'max_features': ['sqrt', 'log2', None], 'criterion': ['squared_Error', 'absolute_error', 'friedman_mse', 'poisson'], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10], 'min_impurity_decrease': [0.0, 0.05, 0.1], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in Random Forest\n",
    "rf_n_estimators = [100,200,300,400,500,600,700,800,900,1000]\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "rf_max_depth = [3,4,5,6,7,8,9,10]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "rf_max_features = ['sqrt', 'log2', None]\n",
    "\n",
    "# Criterion to split on\n",
    "rf_criterion = ['squared_error','absolute_error', 'friedman_mse','poisson']\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "rf_min_samples_split = [2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "# Minimum decrease in impurity required for split to happen\n",
    "rf_min_impurity_decrease = [0.0, 0.05, 0.1]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "rf_bootstrap = [True, False]\n",
    "\n",
    "# Create the grid\n",
    "rf_grid = {'n_estimators': rf_n_estimators,\n",
    "               'max_depth': rf_max_depth,\n",
    "               'max_features': rf_max_features,\n",
    "               'criterion': rf_criterion,\n",
    "               'min_samples_split': rf_min_samples_split,\n",
    "               'min_impurity_decrease': rf_min_impurity_decrease,\n",
    "               'bootstrap': rf_bootstrap}\n",
    "\n",
    "print(rf_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 200 candidates, totalling 600 fits\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=4, max_features=log2, min_impurity_decrease=0.05, min_samples_split=3, n_estimators=800; total time=   0.6s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=4, max_features=log2, min_impurity_decrease=0.05, min_samples_split=3, n_estimators=800; total time=   0.6s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=3, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=9, n_estimators=1000; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=3, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=9, n_estimators=1000; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=4, max_features=log2, min_impurity_decrease=0.05, min_samples_split=3, n_estimators=800; total time=   0.6s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=3, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=9, n_estimators=1000; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=7, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=3, n_estimators=500; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=7, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=3, n_estimators=500; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=9, max_features=None, min_impurity_decrease=0.1, min_samples_split=7, n_estimators=1000; total time=   1.0s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=9, max_features=None, min_impurity_decrease=0.1, min_samples_split=7, n_estimators=1000; total time=   1.1s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=7, max_features=log2, min_impurity_decrease=0.1, min_samples_split=10, n_estimators=500; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=4, max_features=log2, min_impurity_decrease=0.1, min_samples_split=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=7, max_features=log2, min_impurity_decrease=0.1, min_samples_split=10, n_estimators=500; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=7, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=3, n_estimators=500; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=4, max_features=log2, min_impurity_decrease=0.1, min_samples_split=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=4, max_features=log2, min_impurity_decrease=0.1, min_samples_split=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=10, max_features=log2, min_impurity_decrease=0.0, min_samples_split=8, n_estimators=900; total time=   1.5s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=4, max_features=log2, min_impurity_decrease=0.0, min_samples_split=3, n_estimators=400; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=7, max_features=log2, min_impurity_decrease=0.1, min_samples_split=10, n_estimators=500; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=4, max_features=log2, min_impurity_decrease=0.0, min_samples_split=3, n_estimators=400; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=4, max_features=log2, min_impurity_decrease=0.0, min_samples_split=3, n_estimators=400; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=4, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=4, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=10, max_features=log2, min_impurity_decrease=0.0, min_samples_split=8, n_estimators=900; total time=   1.6s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=10, max_features=log2, min_impurity_decrease=0.0, min_samples_split=8, n_estimators=900; total time=   1.8s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=4, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=9, max_features=None, min_impurity_decrease=0.1, min_samples_split=8, n_estimators=700; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=9, max_features=None, min_impurity_decrease=0.1, min_samples_split=8, n_estimators=700; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=9, max_features=None, min_impurity_decrease=0.1, min_samples_split=8, n_estimators=700; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=8, max_features=None, min_impurity_decrease=0.0, min_samples_split=2, n_estimators=500; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=8, max_features=None, min_impurity_decrease=0.0, min_samples_split=2, n_estimators=500; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=8, max_features=None, min_impurity_decrease=0.0, min_samples_split=2, n_estimators=500; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=7, max_features=log2, min_impurity_decrease=0.05, min_samples_split=2, n_estimators=300; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=7, max_features=log2, min_impurity_decrease=0.05, min_samples_split=2, n_estimators=300; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=7, max_features=log2, min_impurity_decrease=0.05, min_samples_split=2, n_estimators=300; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=9, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=9, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=5, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=10, n_estimators=500; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=4, max_features=log2, min_impurity_decrease=0.1, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=4, max_features=log2, min_impurity_decrease=0.1, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=4, max_features=log2, min_impurity_decrease=0.1, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=3, max_features=log2, min_impurity_decrease=0.0, min_samples_split=8, n_estimators=600; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=3, max_features=log2, min_impurity_decrease=0.0, min_samples_split=8, n_estimators=600; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=3, max_features=log2, min_impurity_decrease=0.0, min_samples_split=8, n_estimators=600; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=5, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=10, n_estimators=500; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=9, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=5, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=10, n_estimators=500; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=9, max_features=None, min_impurity_decrease=0.1, min_samples_split=7, n_estimators=1000; total time=   1.4s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=9, max_features=log2, min_impurity_decrease=0.1, min_samples_split=9, n_estimators=100; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=9, max_features=log2, min_impurity_decrease=0.1, min_samples_split=9, n_estimators=100; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=9, max_features=log2, min_impurity_decrease=0.1, min_samples_split=9, n_estimators=100; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=3, max_features=log2, min_impurity_decrease=0.0, min_samples_split=8, n_estimators=800; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=3, max_features=log2, min_impurity_decrease=0.0, min_samples_split=8, n_estimators=800; total time=   0.6s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=9, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=8, max_features=None, min_impurity_decrease=0.05, min_samples_split=10, n_estimators=500; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=3, max_features=log2, min_impurity_decrease=0.0, min_samples_split=8, n_estimators=800; total time=   0.6s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=9, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=8, max_features=None, min_impurity_decrease=0.05, min_samples_split=10, n_estimators=500; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=9, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=8, max_features=None, min_impurity_decrease=0.05, min_samples_split=10, n_estimators=500; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=7, max_features=log2, min_impurity_decrease=0.05, min_samples_split=3, n_estimators=200; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=7, max_features=log2, min_impurity_decrease=0.05, min_samples_split=3, n_estimators=200; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=7, max_features=log2, min_impurity_decrease=0.05, min_samples_split=3, n_estimators=200; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=6, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=8, n_estimators=400; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=6, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=8, n_estimators=400; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=10, max_features=None, min_impurity_decrease=0.0, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=10, max_features=None, min_impurity_decrease=0.0, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=10, max_features=None, min_impurity_decrease=0.0, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=4, max_features=log2, min_impurity_decrease=0.05, min_samples_split=10, n_estimators=900; total time=   0.8s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=4, max_features=log2, min_impurity_decrease=0.05, min_samples_split=10, n_estimators=900; total time=   0.9s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=10, max_features=log2, min_impurity_decrease=0.1, min_samples_split=3, n_estimators=800; total time=   0.6s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=10, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=4, n_estimators=800; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=10, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=4, n_estimators=800; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=10, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=4, n_estimators=800; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=6, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=8, n_estimators=400; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=10, max_features=log2, min_impurity_decrease=0.1, min_samples_split=3, n_estimators=800; total time=   0.6s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=4, max_features=log2, min_impurity_decrease=0.05, min_samples_split=10, n_estimators=900; total time=   0.9s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=8, max_features=None, min_impurity_decrease=0.0, min_samples_split=10, n_estimators=700; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=8, max_features=None, min_impurity_decrease=0.0, min_samples_split=10, n_estimators=700; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=8, max_features=None, min_impurity_decrease=0.0, min_samples_split=10, n_estimators=700; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=4, max_features=log2, min_impurity_decrease=0.0, min_samples_split=5, n_estimators=1000; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=4, max_features=log2, min_impurity_decrease=0.0, min_samples_split=5, n_estimators=1000; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=4, max_features=log2, min_impurity_decrease=0.0, min_samples_split=5, n_estimators=1000; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=5, max_features=log2, min_impurity_decrease=0.0, min_samples_split=6, n_estimators=800; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=5, max_features=log2, min_impurity_decrease=0.0, min_samples_split=6, n_estimators=800; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=5, max_features=log2, min_impurity_decrease=0.0, min_samples_split=6, n_estimators=800; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=10, max_features=log2, min_impurity_decrease=0.1, min_samples_split=3, n_estimators=800; total time=   0.8s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=9, max_features=log2, min_impurity_decrease=0.1, min_samples_split=3, n_estimators=500; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=9, max_features=log2, min_impurity_decrease=0.1, min_samples_split=3, n_estimators=500; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=9, max_features=log2, min_impurity_decrease=0.1, min_samples_split=3, n_estimators=500; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=7, max_features=log2, min_impurity_decrease=0.0, min_samples_split=9, n_estimators=200; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=10, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=2, n_estimators=900; total time=   0.7s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=3, max_features=log2, min_impurity_decrease=0.0, min_samples_split=5, n_estimators=900; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=3, max_features=log2, min_impurity_decrease=0.0, min_samples_split=5, n_estimators=900; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=3, max_features=log2, min_impurity_decrease=0.0, min_samples_split=5, n_estimators=900; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=10, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=2, n_estimators=900; total time=   0.7s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=3, max_features=log2, min_impurity_decrease=0.05, min_samples_split=8, n_estimators=200; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=7, max_features=log2, min_impurity_decrease=0.0, min_samples_split=9, n_estimators=200; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=10, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=2, n_estimators=900; total time=   0.7s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=8, max_features=None, min_impurity_decrease=0.1, min_samples_split=9, n_estimators=1000; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=8, max_features=None, min_impurity_decrease=0.1, min_samples_split=9, n_estimators=1000; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=8, max_features=None, min_impurity_decrease=0.1, min_samples_split=9, n_estimators=1000; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=3, max_features=log2, min_impurity_decrease=0.05, min_samples_split=8, n_estimators=200; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=3, max_features=log2, min_impurity_decrease=0.05, min_samples_split=8, n_estimators=200; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=6, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=2, n_estimators=400; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=6, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=2, n_estimators=400; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=6, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=2, n_estimators=400; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=7, max_features=log2, min_impurity_decrease=0.0, min_samples_split=9, n_estimators=200; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=8, max_features=log2, min_impurity_decrease=0.0, min_samples_split=6, n_estimators=400; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=9, max_features=None, min_impurity_decrease=0.1, min_samples_split=2, n_estimators=400; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=3, max_features=log2, min_impurity_decrease=0.1, min_samples_split=4, n_estimators=900; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=3, max_features=log2, min_impurity_decrease=0.1, min_samples_split=4, n_estimators=900; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=3, max_features=log2, min_impurity_decrease=0.1, min_samples_split=4, n_estimators=900; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=3, max_features=None, min_impurity_decrease=0.05, min_samples_split=10, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=3, max_features=None, min_impurity_decrease=0.05, min_samples_split=10, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=3, max_features=None, min_impurity_decrease=0.05, min_samples_split=10, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=5, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=2, n_estimators=400; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=5, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=2, n_estimators=400; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=5, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=2, n_estimators=400; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=9, max_features=None, min_impurity_decrease=0.1, min_samples_split=2, n_estimators=400; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=7, max_features=None, min_impurity_decrease=0.0, min_samples_split=3, n_estimators=500; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=7, max_features=None, min_impurity_decrease=0.0, min_samples_split=3, n_estimators=500; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=7, max_features=None, min_impurity_decrease=0.0, min_samples_split=3, n_estimators=500; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=4, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=9, n_estimators=1000; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=4, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=9, n_estimators=1000; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=4, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=9, n_estimators=1000; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=8, max_features=log2, min_impurity_decrease=0.0, min_samples_split=6, n_estimators=400; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=8, max_features=log2, min_impurity_decrease=0.0, min_samples_split=6, n_estimators=400; total time=   0.6s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=9, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=6, n_estimators=200; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=9, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=6, n_estimators=200; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=7, max_features=log2, min_impurity_decrease=0.1, min_samples_split=9, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=7, max_features=log2, min_impurity_decrease=0.1, min_samples_split=9, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=7, max_features=log2, min_impurity_decrease=0.1, min_samples_split=9, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=9, max_features=None, min_impurity_decrease=0.1, min_samples_split=2, n_estimators=400; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=9, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=6, n_estimators=200; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=10, max_features=log2, min_impurity_decrease=0.05, min_samples_split=8, n_estimators=200; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=8, max_features=log2, min_impurity_decrease=0.0, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=4, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=6, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=4, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=6, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=4, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=6, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=6, max_features=None, min_impurity_decrease=0.0, min_samples_split=4, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=6, max_features=None, min_impurity_decrease=0.0, min_samples_split=4, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=6, max_features=None, min_impurity_decrease=0.0, min_samples_split=4, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=10, max_features=log2, min_impurity_decrease=0.05, min_samples_split=8, n_estimators=200; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=6, max_features=log2, min_impurity_decrease=0.1, min_samples_split=3, n_estimators=500; total time=   0.6s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=3, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=10, n_estimators=400; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=3, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=10, n_estimators=400; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=3, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=10, n_estimators=400; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=10, max_features=log2, min_impurity_decrease=0.05, min_samples_split=8, n_estimators=200; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=8, max_features=log2, min_impurity_decrease=0.0, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=8, max_features=log2, min_impurity_decrease=0.0, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=6, max_features=log2, min_impurity_decrease=0.1, min_samples_split=3, n_estimators=500; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=8, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=4, n_estimators=800; total time=   1.1s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=10, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=8, n_estimators=1000; total time=   1.3s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=8, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=4, n_estimators=800; total time=   1.3s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=3, max_features=None, min_impurity_decrease=0.1, min_samples_split=10, n_estimators=700; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=3, max_features=None, min_impurity_decrease=0.1, min_samples_split=10, n_estimators=700; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=3, max_features=None, min_impurity_decrease=0.1, min_samples_split=10, n_estimators=700; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=9, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=6, n_estimators=800; total time=   0.7s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=6, max_features=log2, min_impurity_decrease=0.1, min_samples_split=3, n_estimators=500; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=3, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=4, n_estimators=400; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=7, max_features=None, min_impurity_decrease=0.05, min_samples_split=8, n_estimators=300; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=7, max_features=None, min_impurity_decrease=0.1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=7, max_features=None, min_impurity_decrease=0.1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=7, max_features=None, min_impurity_decrease=0.1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=5, max_features=None, min_impurity_decrease=0.1, min_samples_split=3, n_estimators=500; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=7, max_features=None, min_impurity_decrease=0.05, min_samples_split=8, n_estimators=300; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=10, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=8, n_estimators=1000; total time=   1.4s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=9, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=6, n_estimators=800; total time=   0.8s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=4, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=8, n_estimators=300; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=5, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=4, n_estimators=900; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=4, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=8, n_estimators=300; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=4, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=8, n_estimators=300; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=5, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=4, n_estimators=900; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=5, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=4, n_estimators=900; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=6, max_features=log2, min_impurity_decrease=0.05, min_samples_split=2, n_estimators=900; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=6, max_features=log2, min_impurity_decrease=0.05, min_samples_split=2, n_estimators=900; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=6, max_features=log2, min_impurity_decrease=0.05, min_samples_split=2, n_estimators=900; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=7, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=4, n_estimators=200; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=8, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=10, n_estimators=800; total time=   0.6s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=7, max_features=None, min_impurity_decrease=0.05, min_samples_split=8, n_estimators=300; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=9, max_features=None, min_impurity_decrease=0.1, min_samples_split=10, n_estimators=500; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=7, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=4, n_estimators=200; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=5, max_features=None, min_impurity_decrease=0.1, min_samples_split=3, n_estimators=500; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=8, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=4, n_estimators=800; total time=   1.2s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=9, max_features=None, min_impurity_decrease=0.1, min_samples_split=10, n_estimators=500; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=5, max_features=log2, min_impurity_decrease=0.1, min_samples_split=4, n_estimators=800; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=9, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=6, n_estimators=800; total time=   0.8s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=10, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=8, n_estimators=1000; total time=   1.4s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=7, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=4, n_estimators=200; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=3, max_features=log2, min_impurity_decrease=0.1, min_samples_split=5, n_estimators=900; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=3, max_features=log2, min_impurity_decrease=0.1, min_samples_split=5, n_estimators=900; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=3, max_features=log2, min_impurity_decrease=0.05, min_samples_split=2, n_estimators=400; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=3, max_features=log2, min_impurity_decrease=0.05, min_samples_split=2, n_estimators=400; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=3, max_features=log2, min_impurity_decrease=0.05, min_samples_split=2, n_estimators=400; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=9, max_features=log2, min_impurity_decrease=0.05, min_samples_split=7, n_estimators=600; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=9, max_features=log2, min_impurity_decrease=0.05, min_samples_split=7, n_estimators=600; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=9, max_features=log2, min_impurity_decrease=0.05, min_samples_split=7, n_estimators=600; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=8, max_features=None, min_impurity_decrease=0.05, min_samples_split=9, n_estimators=600; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=8, max_features=None, min_impurity_decrease=0.05, min_samples_split=9, n_estimators=600; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=8, max_features=None, min_impurity_decrease=0.05, min_samples_split=9, n_estimators=600; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=4, max_features=None, min_impurity_decrease=0.0, min_samples_split=6, n_estimators=800; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=8, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=10, n_estimators=800; total time=   0.6s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=4, max_features=None, min_impurity_decrease=0.0, min_samples_split=6, n_estimators=800; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=4, max_features=None, min_impurity_decrease=0.0, min_samples_split=6, n_estimators=800; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=6, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=9, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=6, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=9, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=6, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=9, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=6, max_features=log2, min_impurity_decrease=0.0, min_samples_split=8, n_estimators=900; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=6, max_features=log2, min_impurity_decrease=0.0, min_samples_split=8, n_estimators=900; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=6, max_features=log2, min_impurity_decrease=0.0, min_samples_split=8, n_estimators=900; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=5, max_features=None, min_impurity_decrease=0.1, min_samples_split=3, n_estimators=500; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=9, max_features=log2, min_impurity_decrease=0.05, min_samples_split=10, n_estimators=600; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=9, max_features=log2, min_impurity_decrease=0.05, min_samples_split=10, n_estimators=600; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=8, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=2, n_estimators=700; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=8, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=2, n_estimators=700; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=8, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=2, n_estimators=700; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=3, max_features=log2, min_impurity_decrease=0.0, min_samples_split=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=3, max_features=log2, min_impurity_decrease=0.0, min_samples_split=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=5, max_features=log2, min_impurity_decrease=0.1, min_samples_split=4, n_estimators=800; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=9, max_features=None, min_impurity_decrease=0.1, min_samples_split=10, n_estimators=500; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=3, max_features=log2, min_impurity_decrease=0.0, min_samples_split=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=3, max_features=log2, min_impurity_decrease=0.1, min_samples_split=5, n_estimators=900; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=4, max_features=log2, min_impurity_decrease=0.0, min_samples_split=4, n_estimators=1000; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=10, max_features=None, min_impurity_decrease=0.0, min_samples_split=2, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=10, max_features=None, min_impurity_decrease=0.0, min_samples_split=2, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=10, max_features=None, min_impurity_decrease=0.0, min_samples_split=2, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=5, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=6, n_estimators=800; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=10, max_features=None, min_impurity_decrease=0.05, min_samples_split=9, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=10, max_features=None, min_impurity_decrease=0.05, min_samples_split=9, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=10, max_features=None, min_impurity_decrease=0.05, min_samples_split=9, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=7, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=8, n_estimators=800; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=7, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=8, n_estimators=800; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=7, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=8, n_estimators=800; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=4, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=5, n_estimators=600; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=4, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=5, n_estimators=600; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=4, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=5, n_estimators=600; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=5, max_features=None, min_impurity_decrease=0.0, min_samples_split=9, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=5, max_features=None, min_impurity_decrease=0.0, min_samples_split=9, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=3, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=4, n_estimators=400; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=5, max_features=None, min_impurity_decrease=0.0, min_samples_split=9, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=8, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=9, n_estimators=300; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=3, max_features=log2, min_impurity_decrease=0.0, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=10, max_features=log2, min_impurity_decrease=0.05, min_samples_split=4, n_estimators=500; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=3, max_features=log2, min_impurity_decrease=0.0, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=5, max_features=log2, min_impurity_decrease=0.1, min_samples_split=4, n_estimators=800; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=8, max_features=log2, min_impurity_decrease=0.05, min_samples_split=8, n_estimators=800; total time=   0.7s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=8, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=10, n_estimators=800; total time=   0.7s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=4, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=10, n_estimators=700; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=4, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=10, n_estimators=700; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=4, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=10, n_estimators=700; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=3, max_features=log2, min_impurity_decrease=0.0, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=3, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=4, n_estimators=400; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=4, max_features=None, min_impurity_decrease=0.1, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=10, max_features=log2, min_impurity_decrease=0.05, min_samples_split=4, n_estimators=500; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=5, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=6, n_estimators=800; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=5, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=6, n_estimators=800; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=8, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=9, n_estimators=300; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=9, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=3, n_estimators=500; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=10, max_features=log2, min_impurity_decrease=0.1, min_samples_split=8, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=10, max_features=log2, min_impurity_decrease=0.1, min_samples_split=8, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=4, max_features=log2, min_impurity_decrease=0.0, min_samples_split=4, n_estimators=1000; total time=   0.6s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=8, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=5, n_estimators=400; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=9, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=3, n_estimators=500; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=8, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=9, n_estimators=300; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=8, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=5, n_estimators=400; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=8, max_features=log2, min_impurity_decrease=0.05, min_samples_split=8, n_estimators=800; total time=   0.9s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=7, max_features=log2, min_impurity_decrease=0.05, min_samples_split=7, n_estimators=500; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=4, max_features=log2, min_impurity_decrease=0.0, min_samples_split=4, n_estimators=1000; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=9, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=3, n_estimators=500; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=4, max_features=None, min_impurity_decrease=0.1, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=4, max_features=None, min_impurity_decrease=0.1, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=10, max_features=None, min_impurity_decrease=0.0, min_samples_split=4, n_estimators=1000; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=10, max_features=None, min_impurity_decrease=0.0, min_samples_split=4, n_estimators=1000; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=9, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=8, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=5, n_estimators=400; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=10, max_features=log2, min_impurity_decrease=0.1, min_samples_split=8, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=9, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=7, max_features=log2, min_impurity_decrease=0.05, min_samples_split=7, n_estimators=500; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=9, max_features=log2, min_impurity_decrease=0.05, min_samples_split=9, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=9, max_features=log2, min_impurity_decrease=0.05, min_samples_split=9, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=9, max_features=log2, min_impurity_decrease=0.05, min_samples_split=9, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=9, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=10, max_features=None, min_impurity_decrease=0.0, min_samples_split=4, n_estimators=1000; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=5, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=9, n_estimators=100; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=5, max_features=None, min_impurity_decrease=0.0, min_samples_split=2, n_estimators=600; total time=   1.2s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=5, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=9, n_estimators=100; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=7, max_features=log2, min_impurity_decrease=0.05, min_samples_split=7, n_estimators=500; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=8, max_features=None, min_impurity_decrease=0.0, min_samples_split=2, n_estimators=600; total time=   2.1s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=5, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=7, n_estimators=800; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=8, max_features=log2, min_impurity_decrease=0.05, min_samples_split=8, n_estimators=800; total time=   0.8s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=9, max_features=log2, min_impurity_decrease=0.05, min_samples_split=10, n_estimators=600; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=4, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=9, n_estimators=900; total time=   0.6s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=7, max_features=None, min_impurity_decrease=0.0, min_samples_split=9, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=7, max_features=None, min_impurity_decrease=0.0, min_samples_split=9, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=7, max_features=None, min_impurity_decrease=0.0, min_samples_split=9, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=9, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=9, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=4, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=9, n_estimators=900; total time=   0.8s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=9, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=4, max_features=None, min_impurity_decrease=0.05, min_samples_split=5, n_estimators=900; total time=   0.6s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=5, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=7, n_estimators=800; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=4, max_features=None, min_impurity_decrease=0.05, min_samples_split=5, n_estimators=900; total time=   0.7s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=7, max_features=None, min_impurity_decrease=0.0, min_samples_split=3, n_estimators=1000; total time=   0.6s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=4, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=9, n_estimators=900; total time=   0.6s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=5, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=7, n_estimators=800; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=4, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=6, n_estimators=500; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=5, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=9, n_estimators=100; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=9, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=7, n_estimators=500; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=9, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=7, n_estimators=500; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=9, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=7, n_estimators=500; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=5, max_features=None, min_impurity_decrease=0.0, min_samples_split=2, n_estimators=600; total time=   1.3s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=4, max_features=None, min_impurity_decrease=0.05, min_samples_split=5, n_estimators=900; total time=   0.6s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=7, max_features=None, min_impurity_decrease=0.0, min_samples_split=3, n_estimators=1000; total time=   0.8s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=6, max_features=None, min_impurity_decrease=0.1, min_samples_split=2, n_estimators=1000; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=9, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=10, max_features=None, min_impurity_decrease=0.05, min_samples_split=6, n_estimators=600; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=10, max_features=None, min_impurity_decrease=0.05, min_samples_split=6, n_estimators=600; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=10, max_features=None, min_impurity_decrease=0.05, min_samples_split=6, n_estimators=600; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=6, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=9, n_estimators=900; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=6, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=9, n_estimators=900; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=6, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=9, n_estimators=900; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=9, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=9, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=6, max_features=None, min_impurity_decrease=0.1, min_samples_split=2, n_estimators=1000; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=6, max_features=None, min_impurity_decrease=0.1, min_samples_split=2, n_estimators=1000; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=5, max_features=None, min_impurity_decrease=0.05, min_samples_split=7, n_estimators=700; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=6, max_features=None, min_impurity_decrease=0.1, min_samples_split=6, n_estimators=900; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=6, max_features=None, min_impurity_decrease=0.1, min_samples_split=6, n_estimators=900; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=6, max_features=None, min_impurity_decrease=0.1, min_samples_split=6, n_estimators=900; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=9, max_features=None, min_impurity_decrease=0.05, min_samples_split=7, n_estimators=600; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=9, max_features=None, min_impurity_decrease=0.05, min_samples_split=7, n_estimators=600; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=9, max_features=None, min_impurity_decrease=0.05, min_samples_split=7, n_estimators=600; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=7, max_features=None, min_impurity_decrease=0.0, min_samples_split=3, n_estimators=1000; total time=   0.7s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=5, max_features=None, min_impurity_decrease=0.1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=4, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=6, n_estimators=500; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=8, max_features=None, min_impurity_decrease=0.0, min_samples_split=2, n_estimators=600; total time=   1.7s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=5, max_features=None, min_impurity_decrease=0.1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=5, max_features=None, min_impurity_decrease=0.05, min_samples_split=7, n_estimators=700; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=5, max_features=None, min_impurity_decrease=0.1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=9, max_features=log2, min_impurity_decrease=0.05, min_samples_split=2, n_estimators=1000; total time=   0.9s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=4, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=6, n_estimators=500; total time=   0.6s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=5, max_features=None, min_impurity_decrease=0.05, min_samples_split=7, n_estimators=700; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=10, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=9, n_estimators=900; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=10, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=9, n_estimators=900; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=10, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=9, n_estimators=900; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=7, max_features=None, min_impurity_decrease=0.05, min_samples_split=8, n_estimators=700; total time=   1.0s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=7, max_features=None, min_impurity_decrease=0.05, min_samples_split=8, n_estimators=700; total time=   1.1s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=9, max_features=None, min_impurity_decrease=0.1, min_samples_split=4, n_estimators=600; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=9, max_features=None, min_impurity_decrease=0.1, min_samples_split=4, n_estimators=600; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=9, max_features=None, min_impurity_decrease=0.1, min_samples_split=4, n_estimators=600; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=5, max_features=None, min_impurity_decrease=0.0, min_samples_split=2, n_estimators=600; total time=   1.4s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=9, max_features=None, min_impurity_decrease=0.0, min_samples_split=6, n_estimators=800; total time=   0.7s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=5, max_features=log2, min_impurity_decrease=0.05, min_samples_split=10, n_estimators=1000; total time=   0.9s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=9, max_features=None, min_impurity_decrease=0.0, min_samples_split=6, n_estimators=800; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=9, max_features=None, min_impurity_decrease=0.0, min_samples_split=6, n_estimators=800; total time=   0.6s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=9, max_features=log2, min_impurity_decrease=0.0, min_samples_split=7, n_estimators=300; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=10, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=10, n_estimators=1000; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=10, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=10, n_estimators=1000; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=10, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=10, n_estimators=1000; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=4, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=4, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=4, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=5, max_features=log2, min_impurity_decrease=0.0, min_samples_split=5, n_estimators=1000; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=5, max_features=log2, min_impurity_decrease=0.0, min_samples_split=5, n_estimators=1000; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=5, max_features=log2, min_impurity_decrease=0.0, min_samples_split=5, n_estimators=1000; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=6, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=3, n_estimators=700; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=6, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=3, n_estimators=700; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=6, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=3, n_estimators=700; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=4, max_features=log2, min_impurity_decrease=0.1, min_samples_split=4, n_estimators=400; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=4, max_features=log2, min_impurity_decrease=0.1, min_samples_split=4, n_estimators=400; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=4, max_features=log2, min_impurity_decrease=0.1, min_samples_split=4, n_estimators=400; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=8, max_features=log2, min_impurity_decrease=0.1, min_samples_split=5, n_estimators=600; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=8, max_features=log2, min_impurity_decrease=0.1, min_samples_split=5, n_estimators=600; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=8, max_features=log2, min_impurity_decrease=0.1, min_samples_split=5, n_estimators=600; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=9, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=6, n_estimators=1000; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=9, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=6, n_estimators=1000; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=9, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=6, n_estimators=1000; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=9, max_features=log2, min_impurity_decrease=0.0, min_samples_split=7, n_estimators=300; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=5, max_features=log2, min_impurity_decrease=0.05, min_samples_split=10, n_estimators=1000; total time=   1.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=10, max_features=log2, min_impurity_decrease=0.0, min_samples_split=2, n_estimators=700; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=10, max_features=log2, min_impurity_decrease=0.0, min_samples_split=2, n_estimators=700; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=10, max_features=log2, min_impurity_decrease=0.0, min_samples_split=2, n_estimators=700; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=9, max_features=log2, min_impurity_decrease=0.05, min_samples_split=2, n_estimators=1000; total time=   1.1s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=9, max_features=log2, min_impurity_decrease=0.0, min_samples_split=7, n_estimators=300; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=8, max_features=None, min_impurity_decrease=0.0, min_samples_split=2, n_estimators=600; total time=   1.7s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=7, max_features=None, min_impurity_decrease=0.05, min_samples_split=8, n_estimators=700; total time=   1.2s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=3, max_features=log2, min_impurity_decrease=0.05, min_samples_split=8, n_estimators=1000; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=3, max_features=log2, min_impurity_decrease=0.05, min_samples_split=8, n_estimators=1000; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=3, max_features=log2, min_impurity_decrease=0.05, min_samples_split=8, n_estimators=1000; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=8, max_features=None, min_impurity_decrease=0.0, min_samples_split=2, n_estimators=600; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=8, max_features=None, min_impurity_decrease=0.0, min_samples_split=2, n_estimators=600; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=8, max_features=None, min_impurity_decrease=0.0, min_samples_split=2, n_estimators=600; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=4, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=7, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=4, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=7, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=4, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=7, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=8, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=9, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=8, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=9, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=8, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=9, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=7, max_features=log2, min_impurity_decrease=0.0, min_samples_split=9, n_estimators=1000; total time=   0.6s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=7, max_features=log2, min_impurity_decrease=0.0, min_samples_split=9, n_estimators=1000; total time=   0.6s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=10, max_features=log2, min_impurity_decrease=0.05, min_samples_split=4, n_estimators=500; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=4, max_features=None, min_impurity_decrease=0.1, min_samples_split=3, n_estimators=300; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=7, max_features=log2, min_impurity_decrease=0.0, min_samples_split=9, n_estimators=1000; total time=   0.7s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=9, max_features=log2, min_impurity_decrease=0.05, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=9, max_features=log2, min_impurity_decrease=0.05, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=5, max_features=log2, min_impurity_decrease=0.05, min_samples_split=10, n_estimators=1000; total time=   1.1s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=9, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=9, n_estimators=700; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=9, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=9, n_estimators=700; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=4, max_features=None, min_impurity_decrease=0.1, min_samples_split=3, n_estimators=300; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=9, max_features=log2, min_impurity_decrease=0.05, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=4, max_features=None, min_impurity_decrease=0.1, min_samples_split=3, n_estimators=300; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=9, max_features=log2, min_impurity_decrease=0.05, min_samples_split=2, n_estimators=1000; total time=   1.0s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=3, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=3, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=3, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=9, max_features=log2, min_impurity_decrease=0.1, min_samples_split=8, n_estimators=600; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=5, max_features=log2, min_impurity_decrease=0.05, min_samples_split=3, n_estimators=800; total time=   0.6s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=6, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=9, n_estimators=600; total time=   1.1s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=9, max_features=log2, min_impurity_decrease=0.1, min_samples_split=8, n_estimators=600; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=5, max_features=log2, min_impurity_decrease=0.05, min_samples_split=3, n_estimators=800; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=9, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=9, n_estimators=700; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=6, max_features=log2, min_impurity_decrease=0.05, min_samples_split=9, n_estimators=900; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=9, max_features=log2, min_impurity_decrease=0.1, min_samples_split=8, n_estimators=600; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=10, max_features=None, min_impurity_decrease=0.0, min_samples_split=9, n_estimators=200; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=10, max_features=None, min_impurity_decrease=0.0, min_samples_split=9, n_estimators=200; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=10, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=7, n_estimators=300; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=6, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=9, n_estimators=600; total time=   1.1s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=5, max_features=log2, min_impurity_decrease=0.0, min_samples_split=6, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=5, max_features=log2, min_impurity_decrease=0.0, min_samples_split=6, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=3, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=2, n_estimators=600; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=3, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=2, n_estimators=600; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=3, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=2, n_estimators=600; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=4, max_features=None, min_impurity_decrease=0.0, min_samples_split=4, n_estimators=400; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=4, max_features=None, min_impurity_decrease=0.0, min_samples_split=4, n_estimators=400; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=4, max_features=None, min_impurity_decrease=0.0, min_samples_split=4, n_estimators=400; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=5, max_features=log2, min_impurity_decrease=0.05, min_samples_split=3, n_estimators=800; total time=   0.6s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=10, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=7, n_estimators=300; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=5, max_features=log2, min_impurity_decrease=0.0, min_samples_split=6, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=7, max_features=None, min_impurity_decrease=0.1, min_samples_split=3, n_estimators=600; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=7, max_features=None, min_impurity_decrease=0.1, min_samples_split=3, n_estimators=600; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=7, max_features=None, min_impurity_decrease=0.1, min_samples_split=3, n_estimators=600; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=3, max_features=None, min_impurity_decrease=0.0, min_samples_split=3, n_estimators=700; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=3, max_features=None, min_impurity_decrease=0.0, min_samples_split=3, n_estimators=700; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=3, max_features=None, min_impurity_decrease=0.0, min_samples_split=3, n_estimators=700; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=3, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=10, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=3, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=10, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=6, max_features=log2, min_impurity_decrease=0.05, min_samples_split=9, n_estimators=900; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=3, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=10, n_estimators=200; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=6, max_features=log2, min_impurity_decrease=0.05, min_samples_split=9, n_estimators=900; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=10, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=7, n_estimators=500; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=10, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=7, n_estimators=500; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=7, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=10, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=7, n_estimators=300; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=7, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=8, max_features=log2, min_impurity_decrease=0.05, min_samples_split=9, n_estimators=700; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=8, max_features=log2, min_impurity_decrease=0.05, min_samples_split=9, n_estimators=700; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=7, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=8, max_features=log2, min_impurity_decrease=0.05, min_samples_split=9, n_estimators=700; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=10, max_features=None, min_impurity_decrease=0.0, min_samples_split=9, n_estimators=200; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=8, max_features=None, min_impurity_decrease=0.0, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=8, max_features=None, min_impurity_decrease=0.0, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=6, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=9, n_estimators=600; total time=   1.0s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=4, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=7, n_estimators=700; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=4, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=7, n_estimators=700; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=7, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=9, n_estimators=400; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=7, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=9, n_estimators=500; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=8, max_features=None, min_impurity_decrease=0.0, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=6, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=8, n_estimators=1000; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=6, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=8, n_estimators=1000; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=6, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=8, n_estimators=1000; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=8, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=10, n_estimators=900; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=8, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=10, n_estimators=900; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=8, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=10, n_estimators=900; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=6, max_features=None, min_impurity_decrease=0.0, min_samples_split=10, n_estimators=700; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=7, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=9, n_estimators=500; total time=   0.6s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=3, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=6, n_estimators=800; total time=   0.8s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=10, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=7, n_estimators=500; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=6, max_features=None, min_impurity_decrease=0.0, min_samples_split=10, n_estimators=700; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=8, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=4, n_estimators=300; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=7, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=9, n_estimators=400; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=8, max_features=None, min_impurity_decrease=0.0, min_samples_split=8, n_estimators=500; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=8, max_features=None, min_impurity_decrease=0.0, min_samples_split=8, n_estimators=500; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=4, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=7, n_estimators=700; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=3, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=6, n_estimators=800; total time=   1.0s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=8, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=4, n_estimators=300; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=8, max_features=None, min_impurity_decrease=0.0, min_samples_split=8, n_estimators=500; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=8, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=4, n_estimators=300; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=9, max_features=log2, min_impurity_decrease=0.0, min_samples_split=8, n_estimators=800; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=9, max_features=log2, min_impurity_decrease=0.0, min_samples_split=8, n_estimators=800; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=9, max_features=log2, min_impurity_decrease=0.0, min_samples_split=8, n_estimators=800; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=8, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=9, n_estimators=900; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=8, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=9, n_estimators=900; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=8, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=9, n_estimators=900; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=10, max_features=log2, min_impurity_decrease=0.1, min_samples_split=7, n_estimators=500; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=10, max_features=log2, min_impurity_decrease=0.1, min_samples_split=7, n_estimators=500; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=10, max_features=log2, min_impurity_decrease=0.1, min_samples_split=7, n_estimators=500; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=8, max_features=None, min_impurity_decrease=0.0, min_samples_split=8, n_estimators=1000; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=8, max_features=None, min_impurity_decrease=0.0, min_samples_split=8, n_estimators=1000; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=8, max_features=None, min_impurity_decrease=0.0, min_samples_split=8, n_estimators=1000; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=3, max_features=log2, min_impurity_decrease=0.0, min_samples_split=5, n_estimators=600; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=3, max_features=log2, min_impurity_decrease=0.0, min_samples_split=5, n_estimators=600; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=3, max_features=log2, min_impurity_decrease=0.0, min_samples_split=5, n_estimators=600; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=3, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=7, n_estimators=900; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=3, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=7, n_estimators=900; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=3, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=7, n_estimators=900; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=9, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=3, n_estimators=900; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=9, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=3, n_estimators=900; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=9, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=3, n_estimators=900; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=7, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=9, n_estimators=400; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=6, max_features=None, min_impurity_decrease=0.05, min_samples_split=7, n_estimators=100; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=6, max_features=None, min_impurity_decrease=0.0, min_samples_split=10, n_estimators=700; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=7, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=9, n_estimators=500; total time=   0.6s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=6, max_features=None, min_impurity_decrease=0.05, min_samples_split=7, n_estimators=100; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=4, max_features=log2, min_impurity_decrease=0.1, min_samples_split=8, n_estimators=700; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=4, max_features=log2, min_impurity_decrease=0.1, min_samples_split=8, n_estimators=700; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=6, max_features=None, min_impurity_decrease=0.05, min_samples_split=7, n_estimators=100; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=3, max_features=log2, min_impurity_decrease=0.1, min_samples_split=6, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=3, max_features=log2, min_impurity_decrease=0.1, min_samples_split=6, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=3, max_features=log2, min_impurity_decrease=0.1, min_samples_split=6, n_estimators=300; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=7, max_features=None, min_impurity_decrease=0.1, min_samples_split=3, n_estimators=700; total time=   0.6s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=10, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=8, n_estimators=500; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=7, max_features=None, min_impurity_decrease=0.1, min_samples_split=3, n_estimators=700; total time=   0.7s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=3, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=6, n_estimators=800; total time=   0.9s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=9, max_features=None, min_impurity_decrease=0.1, min_samples_split=9, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=9, max_features=None, min_impurity_decrease=0.1, min_samples_split=9, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=9, max_features=None, min_impurity_decrease=0.1, min_samples_split=9, n_estimators=100; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=4, max_features=log2, min_impurity_decrease=0.1, min_samples_split=8, n_estimators=700; total time=   0.6s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=4, max_features=log2, min_impurity_decrease=0.0, min_samples_split=10, n_estimators=600; total time=   0.8s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=4, max_features=log2, min_impurity_decrease=0.0, min_samples_split=10, n_estimators=600; total time=   0.8s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=10, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=8, n_estimators=500; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=6, max_features=log2, min_impurity_decrease=0.1, min_samples_split=3, n_estimators=800; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=6, max_features=log2, min_impurity_decrease=0.1, min_samples_split=3, n_estimators=800; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=6, max_features=log2, min_impurity_decrease=0.1, min_samples_split=3, n_estimators=800; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=10, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=5, n_estimators=1000; total time=   0.7s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=10, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=5, n_estimators=1000; total time=   0.7s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=10, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=8, n_estimators=500; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=9, max_features=None, min_impurity_decrease=0.05, min_samples_split=4, n_estimators=500; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=7, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=4, n_estimators=500; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=4, max_features=log2, min_impurity_decrease=0.0, min_samples_split=10, n_estimators=600; total time=   0.7s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=9, max_features=None, min_impurity_decrease=0.1, min_samples_split=5, n_estimators=400; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=9, max_features=None, min_impurity_decrease=0.1, min_samples_split=5, n_estimators=400; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=5, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=8, n_estimators=700; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=5, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=8, n_estimators=700; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=5, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=8, n_estimators=700; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=3, max_features=None, min_impurity_decrease=0.1, min_samples_split=7, n_estimators=900; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=3, max_features=None, min_impurity_decrease=0.1, min_samples_split=7, n_estimators=900; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=3, max_features=None, min_impurity_decrease=0.1, min_samples_split=7, n_estimators=900; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=5, max_features=None, min_impurity_decrease=0.0, min_samples_split=2, n_estimators=600; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=5, max_features=None, min_impurity_decrease=0.0, min_samples_split=2, n_estimators=600; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=squared_Error, max_depth=5, max_features=None, min_impurity_decrease=0.0, min_samples_split=2, n_estimators=600; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=7, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=4, n_estimators=500; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=9, max_features=None, min_impurity_decrease=0.1, min_samples_split=5, n_estimators=400; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=7, max_features=None, min_impurity_decrease=0.1, min_samples_split=3, n_estimators=700; total time=   1.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=6, max_features=None, min_impurity_decrease=0.05, min_samples_split=9, n_estimators=1000; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=6, max_features=None, min_impurity_decrease=0.05, min_samples_split=9, n_estimators=1000; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=6, max_features=None, min_impurity_decrease=0.05, min_samples_split=9, n_estimators=1000; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=8, max_features=log2, min_impurity_decrease=0.0, min_samples_split=3, n_estimators=600; total time=   0.9s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=8, max_features=log2, min_impurity_decrease=0.0, min_samples_split=3, n_estimators=600; total time=   1.1s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=9, max_features=None, min_impurity_decrease=0.05, min_samples_split=4, n_estimators=500; total time=   0.7s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=5, max_features=None, min_impurity_decrease=0.0, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=7, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=4, n_estimators=500; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=5, max_features=None, min_impurity_decrease=0.0, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=10, max_features=sqrt, min_impurity_decrease=0.05, min_samples_split=5, n_estimators=1000; total time=   0.7s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=5, max_features=log2, min_impurity_decrease=0.1, min_samples_split=9, n_estimators=700; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=5, max_features=log2, min_impurity_decrease=0.1, min_samples_split=9, n_estimators=700; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=9, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=7, n_estimators=500; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=9, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=7, n_estimators=500; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=squared_Error, max_depth=9, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=7, n_estimators=500; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=7, max_features=None, min_impurity_decrease=0.1, min_samples_split=7, n_estimators=100; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=10, max_features=log2, min_impurity_decrease=0.05, min_samples_split=7, n_estimators=600; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=7, max_features=None, min_impurity_decrease=0.1, min_samples_split=7, n_estimators=100; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=5, max_features=None, min_impurity_decrease=0.0, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=8, max_features=log2, min_impurity_decrease=0.05, min_samples_split=5, n_estimators=600; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=8, max_features=log2, min_impurity_decrease=0.05, min_samples_split=5, n_estimators=600; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=poisson, max_depth=8, max_features=log2, min_impurity_decrease=0.05, min_samples_split=5, n_estimators=600; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=7, max_features=None, min_impurity_decrease=0.1, min_samples_split=7, n_estimators=100; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=10, max_features=log2, min_impurity_decrease=0.05, min_samples_split=7, n_estimators=600; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=5, max_features=log2, min_impurity_decrease=0.1, min_samples_split=9, n_estimators=700; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=6, max_features=log2, min_impurity_decrease=0.0, min_samples_split=6, n_estimators=900; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=6, max_features=log2, min_impurity_decrease=0.0, min_samples_split=6, n_estimators=900; total time=   0.6s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=10, max_features=log2, min_impurity_decrease=0.05, min_samples_split=7, n_estimators=600; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=8, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=9, n_estimators=700; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=8, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=9, n_estimators=700; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=9, max_features=None, min_impurity_decrease=0.05, min_samples_split=4, n_estimators=500; total time=   0.7s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=8, max_features=log2, min_impurity_decrease=0.0, min_samples_split=3, n_estimators=600; total time=   0.9s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=10, max_features=None, min_impurity_decrease=0.0, min_samples_split=7, n_estimators=600; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=8, max_features=log2, min_impurity_decrease=0.0, min_samples_split=5, n_estimators=400; total time=   0.6s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=10, max_features=None, min_impurity_decrease=0.0, min_samples_split=7, n_estimators=600; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=poisson, max_depth=8, max_features=sqrt, min_impurity_decrease=0.1, min_samples_split=9, n_estimators=700; total time=   0.0s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=8, max_features=log2, min_impurity_decrease=0.0, min_samples_split=5, n_estimators=400; total time=   0.6s\n",
      "[CV] END bootstrap=False, criterion=friedman_mse, max_depth=6, max_features=log2, min_impurity_decrease=0.0, min_samples_split=6, n_estimators=900; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=10, max_features=None, min_impurity_decrease=0.0, min_samples_split=7, n_estimators=600; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=8, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=4, n_estimators=1000; total time=   0.6s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=8, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=4, n_estimators=1000; total time=   0.7s\n",
      "[CV] END bootstrap=True, criterion=absolute_error, max_depth=8, max_features=log2, min_impurity_decrease=0.0, min_samples_split=5, n_estimators=400; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=8, max_features=None, min_impurity_decrease=0.1, min_samples_split=7, n_estimators=900; total time=   0.7s\n",
      "[CV] END bootstrap=True, criterion=friedman_mse, max_depth=8, max_features=sqrt, min_impurity_decrease=0.0, min_samples_split=4, n_estimators=1000; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=8, max_features=None, min_impurity_decrease=0.1, min_samples_split=7, n_estimators=900; total time=   0.6s\n",
      "[CV] END bootstrap=False, criterion=absolute_error, max_depth=8, max_features=None, min_impurity_decrease=0.1, min_samples_split=7, n_estimators=900; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "303 fits failed out of a total of 600.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 340, in fit\n",
      "    self._validate_params()\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of RandomForestRegressor must be a str among {'absolute_error', 'poisson', 'squared_error', 'friedman_mse'}. Got 'squared_Error' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "138 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 373, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Some value(s) of y are negative which is not allowed for Poisson regression.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 340, in fit\n",
      "    self._validate_params()\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of RandomForestRegressor must be a str among {'friedman_mse', 'squared_error', 'poisson', 'absolute_error'}. Got 'squared_Error' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 340, in fit\n",
      "    self._validate_params()\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of RandomForestRegressor must be a str among {'squared_error', 'absolute_error', 'poisson', 'friedman_mse'}. Got 'squared_Error' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "27 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 340, in fit\n",
      "    self._validate_params()\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of RandomForestRegressor must be a str among {'poisson', 'absolute_error', 'squared_error', 'friedman_mse'}. Got 'squared_Error' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 340, in fit\n",
      "    self._validate_params()\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of RandomForestRegressor must be a str among {'poisson', 'friedman_mse', 'squared_error', 'absolute_error'}. Got 'squared_Error' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "33 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 340, in fit\n",
      "    self._validate_params()\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of RandomForestRegressor must be a str among {'absolute_error', 'poisson', 'friedman_mse', 'squared_error'}. Got 'squared_Error' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "33 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 340, in fit\n",
      "    self._validate_params()\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of RandomForestRegressor must be a str among {'squared_error', 'friedman_mse', 'absolute_error', 'poisson'}. Got 'squared_Error' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "13 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 340, in fit\n",
      "    self._validate_params()\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of RandomForestRegressor must be a str among {'absolute_error', 'friedman_mse', 'squared_error', 'poisson'}. Got 'squared_Error' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [ 0.24886969  0.28884662  0.09367152         nan  0.30146456  0.30485193\n",
      "  0.2935407   0.17611934         nan  0.28576861  0.29599957         nan\n",
      "         nan  0.27236618  0.22201888         nan         nan  0.27799079\n",
      "  0.28035562  0.17649888  0.22964363  0.27283341 -0.04482167  0.30479745\n",
      "         nan  0.27209183         nan  0.28125891         nan         nan\n",
      "         nan  0.25696267  0.17152766         nan  0.28945764  0.28897115\n",
      "         nan -0.07150067         nan  0.28078618         nan         nan\n",
      "         nan         nan         nan -0.04486674 -0.04488224         nan\n",
      "         nan  0.18236431         nan         nan         nan  0.03477629\n",
      "  0.22493148 -0.04505206         nan  0.21501278  0.19742012  0.28220285\n",
      "         nan  0.28794979         nan  0.28857248         nan  0.30017736\n",
      "  0.29117599         nan  0.22465832         nan         nan         nan\n",
      "         nan         nan         nan         nan  0.14574381         nan\n",
      "         nan  0.2856682  -0.02268619  0.28330064         nan         nan\n",
      "         nan         nan         nan  0.22337068         nan  0.17584768\n",
      "         nan  0.13061646  0.29050098         nan  0.14444705         nan\n",
      "  0.25148299         nan  0.28972324         nan  0.2976586   0.3007814\n",
      "  0.28277264  0.17385306  0.23370815  0.09783972  0.19053838         nan\n",
      "         nan  0.28856216         nan  0.14331624         nan         nan\n",
      "  0.11941357         nan         nan  0.19742012  0.14344976         nan\n",
      "         nan  0.00948119  0.29219            nan         nan         nan\n",
      "         nan         nan         nan         nan  0.29125363  0.25846409\n",
      "         nan         nan         nan         nan  0.08565625  0.16261841\n",
      "  0.29764044         nan  0.2710212   0.2997914   0.27424968  0.26453109\n",
      " -0.04639343         nan         nan         nan         nan  0.29194039\n",
      "         nan         nan  0.25504149         nan  0.03795015         nan\n",
      "  0.14553933         nan  0.2908436   0.29157617         nan         nan\n",
      "  0.25338688         nan  0.28989029  0.11941357         nan         nan\n",
      "         nan         nan         nan         nan         nan -0.09628352\n",
      "  0.26993614  0.29549956         nan  0.23248433         nan  0.28032998\n",
      "         nan  0.21229799  0.27738089         nan         nan         nan\n",
      "         nan  0.14168891         nan  0.29422914  0.2537574          nan\n",
      "         nan  0.11745294         nan  0.28235937  0.2814366          nan\n",
      "  0.29223252 -0.09628352]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 500,\n",
       " 'min_samples_split': 10,\n",
       " 'min_impurity_decrease': 0.1,\n",
       " 'max_features': 'log2',\n",
       " 'max_depth': 7,\n",
       " 'criterion': 'friedman_mse',\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model to be tuned\n",
    "rf_base = RandomForestRegressor()\n",
    "\n",
    "# Create the random search Random Forest\n",
    "rf_random = RandomizedSearchCV(estimator = rf_base, param_distributions = rf_grid, \n",
    "                               n_iter = 200, cv = 3, verbose = 2, random_state = 100, \n",
    "                               n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train_temp, y_train_temp)\n",
    "\n",
    "# View the best parameters from the random search\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_depth': [2, 4, 6, 8, 10, 12, 14, 16, 18, 20], 'min_child_weight': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'tree_method': ['auto', 'exact', 'approx', 'hist', 'gpu_hist'], 'eta': [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.6], 'gamma': [0, 0, 0, 0, 0, 0], 'objective': ['reg:squarederror', 'reg:squaredlogerror']}\n"
     ]
    }
   ],
   "source": [
    "# Number of trees to be used\n",
    "xgb_n_estimators = [int(x) for x in np.linspace(200, 2000, 10)]\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "xgb_max_depth = [int(x) for x in np.linspace(2, 20, 10)]\n",
    "\n",
    "# Minimum number of instaces needed in each node\n",
    "xgb_min_child_weight = [int(x) for x in np.linspace(1, 10, 10)]\n",
    "\n",
    "# Tree construction algorithm used in XGBoost\n",
    "xgb_tree_method = ['auto', 'exact', 'approx', 'hist', 'gpu_hist']\n",
    "\n",
    "# Learning rate\n",
    "xgb_eta = [x for x in np.linspace(0.1, 0.6, 6)]\n",
    "\n",
    "# Minimum loss reduction required to make further partition\n",
    "xgb_gamma = [int(x) for x in np.linspace(0, 0.5, 6)]\n",
    "\n",
    "# Learning objective used\n",
    "xgb_objective = ['reg:squarederror', 'reg:squaredlogerror']\n",
    "\n",
    "# Create the grid\n",
    "xgb_grid = {'n_estimators': xgb_n_estimators,\n",
    "            'max_depth': xgb_max_depth,\n",
    "            'min_child_weight': xgb_min_child_weight,\n",
    "            'tree_method': xgb_tree_method,\n",
    "            'eta': xgb_eta,\n",
    "            'gamma': xgb_gamma,\n",
    "            'objective': xgb_objective}\n",
    "\n",
    "print(xgb_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 200 candidates, totalling 600 fits\n",
      "[CV] END eta=0.1, gamma=0, max_depth=14, min_child_weight=1, n_estimators=1800, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=2, min_child_weight=8, n_estimators=1200, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=2, min_child_weight=8, n_estimators=1200, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=14, min_child_weight=1, n_estimators=1800, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=14, min_child_weight=1, n_estimators=1800, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=8, min_child_weight=8, n_estimators=2000, objective=reg:squaredlogerror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=2, min_child_weight=8, n_estimators=1200, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=8, min_child_weight=8, n_estimators=2000, objective=reg:squaredlogerror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=8, min_child_weight=8, n_estimators=2000, objective=reg:squaredlogerror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=20, min_child_weight=8, n_estimators=2000, objective=reg:squaredlogerror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=20, min_child_weight=8, n_estimators=2000, objective=reg:squaredlogerror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=12, min_child_weight=7, n_estimators=400, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=20, min_child_weight=8, n_estimators=2000, objective=reg:squaredlogerror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=12, min_child_weight=7, n_estimators=400, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=12, min_child_weight=7, n_estimators=400, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=10, min_child_weight=5, n_estimators=400, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=10, min_child_weight=5, n_estimators=400, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=10, min_child_weight=5, n_estimators=400, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=6, min_child_weight=7, n_estimators=1600, objective=reg:squaredlogerror, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=6, min_child_weight=7, n_estimators=1600, objective=reg:squaredlogerror, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=6, min_child_weight=7, n_estimators=1600, objective=reg:squaredlogerror, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=6, min_child_weight=10, n_estimators=400, objective=reg:squarederror, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=2, min_child_weight=6, n_estimators=1200, objective=reg:squarederror, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=2, min_child_weight=6, n_estimators=1200, objective=reg:squarederror, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=20, min_child_weight=3, n_estimators=2000, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=20, min_child_weight=3, n_estimators=2000, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=20, min_child_weight=3, n_estimators=2000, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=3, n_estimators=2000, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=3, n_estimators=2000, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=3, n_estimators=2000, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=6, min_child_weight=10, n_estimators=400, objective=reg:squarederror, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=8, min_child_weight=10, n_estimators=800, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=8, min_child_weight=10, n_estimators=800, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=6, min_child_weight=3, n_estimators=1200, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=6, min_child_weight=3, n_estimators=1200, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=2, min_child_weight=4, n_estimators=400, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=2, min_child_weight=4, n_estimators=400, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=2, min_child_weight=6, n_estimators=1200, objective=reg:squarederror, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=20, min_child_weight=5, n_estimators=1200, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=20, min_child_weight=5, n_estimators=1200, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=8, min_child_weight=10, n_estimators=800, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=2, min_child_weight=4, n_estimators=400, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=6, min_child_weight=10, n_estimators=400, objective=reg:squarederror, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=12, min_child_weight=5, n_estimators=600, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=10, min_child_weight=5, n_estimators=1000, objective=reg:squarederror, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=12, min_child_weight=5, n_estimators=600, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=12, min_child_weight=5, n_estimators=600, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=4, min_child_weight=7, n_estimators=1400, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=4, min_child_weight=7, n_estimators=1400, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=4, min_child_weight=7, n_estimators=1400, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=3, n_estimators=400, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=3, n_estimators=400, objective=reg:squarederror, tree_method=auto; total time=   0.2s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=6, min_child_weight=3, n_estimators=1200, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=18, min_child_weight=9, n_estimators=400, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=10, min_child_weight=5, n_estimators=1000, objective=reg:squarederror, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=8, min_child_weight=6, n_estimators=1400, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=8, min_child_weight=6, n_estimators=1400, objective=reg:squarederror, tree_method=hist; total time=   0.2s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=10, min_child_weight=5, n_estimators=1000, objective=reg:squarederror, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=20, min_child_weight=1, n_estimators=1000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=20, min_child_weight=1, n_estimators=1000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=16, min_child_weight=2, n_estimators=800, objective=reg:squaredlogerror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=16, min_child_weight=2, n_estimators=800, objective=reg:squaredlogerror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=16, min_child_weight=2, n_estimators=800, objective=reg:squaredlogerror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=4, min_child_weight=3, n_estimators=200, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=20, min_child_weight=2, n_estimators=1800, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=4, min_child_weight=3, n_estimators=200, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=4, min_child_weight=3, n_estimators=200, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=8, min_child_weight=2, n_estimators=800, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=3, n_estimators=400, objective=reg:squarederror, tree_method=auto; total time=   0.2s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=6, min_child_weight=10, n_estimators=1800, objective=reg:squaredlogerror, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=6, min_child_weight=10, n_estimators=1800, objective=reg:squaredlogerror, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=16, min_child_weight=8, n_estimators=1200, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=16, min_child_weight=8, n_estimators=1200, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=16, min_child_weight=8, n_estimators=1200, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=4, n_estimators=200, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=4, n_estimators=200, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=4, n_estimators=200, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=18, min_child_weight=9, n_estimators=400, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=20, min_child_weight=2, n_estimators=1800, objective=reg:squarederror, tree_method=hist; total time=   0.2s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=8, min_child_weight=2, n_estimators=800, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=20, min_child_weight=2, n_estimators=1800, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=8, min_child_weight=6, n_estimators=1400, objective=reg:squarederror, tree_method=hist; total time=   0.2s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=16, min_child_weight=2, n_estimators=1400, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=16, min_child_weight=2, n_estimators=1400, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=12, min_child_weight=7, n_estimators=1800, objective=reg:squaredlogerror, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=18, min_child_weight=9, n_estimators=400, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=8, min_child_weight=2, n_estimators=800, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=12, min_child_weight=7, n_estimators=1800, objective=reg:squaredlogerror, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=20, min_child_weight=5, n_estimators=1200, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=6, min_child_weight=4, n_estimators=400, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=6, min_child_weight=4, n_estimators=400, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=10, min_child_weight=8, n_estimators=200, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=6, min_child_weight=4, n_estimators=400, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=10, min_child_weight=8, n_estimators=200, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=10, min_child_weight=8, n_estimators=200, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=12, min_child_weight=7, n_estimators=1800, objective=reg:squaredlogerror, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=8, min_child_weight=10, n_estimators=200, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=12, min_child_weight=9, n_estimators=2000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=12, min_child_weight=3, n_estimators=2000, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=12, min_child_weight=9, n_estimators=2000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=12, min_child_weight=9, n_estimators=2000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=12, min_child_weight=3, n_estimators=2000, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=4, min_child_weight=5, n_estimators=1200, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=12, min_child_weight=3, n_estimators=2000, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=10, min_child_weight=8, n_estimators=400, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=10, min_child_weight=8, n_estimators=400, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=10, min_child_weight=8, n_estimators=400, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=4, min_child_weight=5, n_estimators=1200, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=4, min_child_weight=5, n_estimators=1200, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=4, min_child_weight=9, n_estimators=1600, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=4, min_child_weight=9, n_estimators=1600, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=18, min_child_weight=7, n_estimators=600, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=10, min_child_weight=8, n_estimators=1200, objective=reg:squaredlogerror, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=18, min_child_weight=7, n_estimators=600, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=10, min_child_weight=8, n_estimators=1200, objective=reg:squaredlogerror, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=10, min_child_weight=8, n_estimators=1200, objective=reg:squaredlogerror, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=14, min_child_weight=4, n_estimators=1000, objective=reg:squaredlogerror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=14, min_child_weight=4, n_estimators=1000, objective=reg:squaredlogerror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=14, min_child_weight=4, n_estimators=1000, objective=reg:squaredlogerror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=4, min_child_weight=9, n_estimators=1600, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=10, min_child_weight=8, n_estimators=1400, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=10, min_child_weight=8, n_estimators=1400, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=8, min_child_weight=6, n_estimators=600, objective=reg:squarederror, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=10, min_child_weight=8, n_estimators=1400, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=6, min_child_weight=1, n_estimators=1000, objective=reg:squaredlogerror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=6, min_child_weight=1, n_estimators=1000, objective=reg:squaredlogerror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=18, min_child_weight=7, n_estimators=600, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=6, min_child_weight=1, n_estimators=1000, objective=reg:squaredlogerror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=14, min_child_weight=6, n_estimators=2000, objective=reg:squaredlogerror, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=14, min_child_weight=6, n_estimators=2000, objective=reg:squaredlogerror, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=4, min_child_weight=8, n_estimators=1000, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=14, min_child_weight=6, n_estimators=2000, objective=reg:squaredlogerror, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=4, min_child_weight=8, n_estimators=1000, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=4, min_child_weight=8, n_estimators=1000, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=4, min_child_weight=10, n_estimators=1000, objective=reg:squaredlogerror, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=3, n_estimators=2000, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=4, min_child_weight=10, n_estimators=1000, objective=reg:squaredlogerror, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=4, min_child_weight=10, n_estimators=1000, objective=reg:squaredlogerror, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=3, n_estimators=2000, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=3, n_estimators=2000, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=6, min_child_weight=3, n_estimators=1400, objective=reg:squaredlogerror, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=6, min_child_weight=3, n_estimators=1400, objective=reg:squaredlogerror, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=6, min_child_weight=3, n_estimators=1400, objective=reg:squaredlogerror, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=6, min_child_weight=4, n_estimators=400, objective=reg:squarederror, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=2, min_child_weight=7, n_estimators=1600, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=2, min_child_weight=7, n_estimators=1600, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=2, min_child_weight=7, n_estimators=1600, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=6, min_child_weight=4, n_estimators=400, objective=reg:squarederror, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=10, min_child_weight=10, n_estimators=1800, objective=reg:squarederror, tree_method=auto; total time=   0.3s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=8, min_child_weight=6, n_estimators=600, objective=reg:squarederror, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=10, min_child_weight=10, n_estimators=1400, objective=reg:squarederror, tree_method=exact; total time=   0.3s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=6, min_child_weight=4, n_estimators=400, objective=reg:squarederror, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=12, min_child_weight=10, n_estimators=800, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=12, min_child_weight=10, n_estimators=800, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=12, min_child_weight=10, n_estimators=800, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=8, min_child_weight=10, n_estimators=200, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=8, min_child_weight=10, n_estimators=200, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=6, min_child_weight=9, n_estimators=1200, objective=reg:squarederror, tree_method=hist; total time=   0.2s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=8, min_child_weight=6, n_estimators=600, objective=reg:squarederror, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=12, min_child_weight=10, n_estimators=1800, objective=reg:squarederror, tree_method=exact; total time=   0.5s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=2, min_child_weight=3, n_estimators=1600, objective=reg:squarederror, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=16, min_child_weight=3, n_estimators=400, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=4, min_child_weight=6, n_estimators=1400, objective=reg:squarederror, tree_method=auto; total time=   0.3s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=2, min_child_weight=3, n_estimators=1600, objective=reg:squarederror, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=6, min_child_weight=10, n_estimators=1800, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=6, min_child_weight=10, n_estimators=1800, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=6, min_child_weight=10, n_estimators=1800, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=2, min_child_weight=2, n_estimators=1200, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=8, min_child_weight=5, n_estimators=1800, objective=reg:squarederror, tree_method=auto; total time=   0.4s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=2, min_child_weight=2, n_estimators=1200, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=2, min_child_weight=2, n_estimators=1200, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=16, min_child_weight=3, n_estimators=400, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=6, min_child_weight=8, n_estimators=800, objective=reg:squaredlogerror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=16, min_child_weight=10, n_estimators=1200, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=16, min_child_weight=10, n_estimators=1200, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=16, min_child_weight=10, n_estimators=1200, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=10, min_child_weight=10, n_estimators=1800, objective=reg:squarederror, tree_method=auto; total time=   0.3s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=6, min_child_weight=9, n_estimators=1200, objective=reg:squarederror, tree_method=hist; total time=   0.2s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=16, min_child_weight=3, n_estimators=400, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=14, min_child_weight=7, n_estimators=2000, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=14, min_child_weight=7, n_estimators=2000, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=14, min_child_weight=7, n_estimators=2000, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=6, min_child_weight=8, n_estimators=800, objective=reg:squaredlogerror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=6, min_child_weight=8, n_estimators=800, objective=reg:squaredlogerror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=14, min_child_weight=3, n_estimators=2000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=14, min_child_weight=3, n_estimators=2000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=10, min_child_weight=10, n_estimators=1400, objective=reg:squarederror, tree_method=exact; total time=   0.3s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=18, min_child_weight=9, n_estimators=400, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=6, min_child_weight=9, n_estimators=1200, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=2, min_child_weight=1, n_estimators=2000, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=2, min_child_weight=1, n_estimators=2000, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=2, min_child_weight=1, n_estimators=2000, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=20, min_child_weight=3, n_estimators=600, objective=reg:squarederror, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=4, min_child_weight=6, n_estimators=1400, objective=reg:squarederror, tree_method=auto; total time=   0.3s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=10, min_child_weight=10, n_estimators=1800, objective=reg:squarederror, tree_method=auto; total time=   0.2s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=6, min_child_weight=10, n_estimators=1800, objective=reg:squaredlogerror, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=10, min_child_weight=6, n_estimators=2000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=18, min_child_weight=9, n_estimators=400, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=10, min_child_weight=6, n_estimators=2000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=10, min_child_weight=6, n_estimators=2000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=12, min_child_weight=10, n_estimators=1800, objective=reg:squarederror, tree_method=exact; total time=   0.4s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=2, min_child_weight=3, n_estimators=1600, objective=reg:squarederror, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=20, min_child_weight=2, n_estimators=600, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=14, min_child_weight=1, n_estimators=800, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=14, min_child_weight=1, n_estimators=800, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=14, min_child_weight=1, n_estimators=800, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=2, min_child_weight=2, n_estimators=200, objective=reg:squarederror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=18, min_child_weight=9, n_estimators=400, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=14, min_child_weight=3, n_estimators=2000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=20, min_child_weight=3, n_estimators=600, objective=reg:squarederror, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=6, min_child_weight=8, n_estimators=1200, objective=reg:squaredlogerror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=6, min_child_weight=8, n_estimators=1200, objective=reg:squaredlogerror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=18, min_child_weight=4, n_estimators=600, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=18, min_child_weight=4, n_estimators=600, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=18, min_child_weight=4, n_estimators=600, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=2, min_child_weight=2, n_estimators=200, objective=reg:squarederror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=6, min_child_weight=1, n_estimators=1600, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=2, min_child_weight=2, n_estimators=200, objective=reg:squarederror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=6, min_child_weight=8, n_estimators=1200, objective=reg:squaredlogerror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=20, min_child_weight=2, n_estimators=1400, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=20, min_child_weight=2, n_estimators=1400, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=20, min_child_weight=2, n_estimators=1400, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=10, min_child_weight=10, n_estimators=1400, objective=reg:squarederror, tree_method=exact; total time=   0.3s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=16, min_child_weight=2, n_estimators=1400, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=8, min_child_weight=7, n_estimators=1600, objective=reg:squaredlogerror, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=8, min_child_weight=7, n_estimators=1600, objective=reg:squaredlogerror, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=4, min_child_weight=6, n_estimators=1400, objective=reg:squarederror, tree_method=auto; total time=   0.2s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=16, min_child_weight=5, n_estimators=600, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=8, min_child_weight=5, n_estimators=1800, objective=reg:squarederror, tree_method=auto; total time=   0.5s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=20, min_child_weight=3, n_estimators=600, objective=reg:squarederror, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=10, min_child_weight=9, n_estimators=600, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=6, min_child_weight=8, n_estimators=200, objective=reg:squarederror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=6, min_child_weight=1, n_estimators=1600, objective=reg:squarederror, tree_method=hist; total time=   0.2s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=6, min_child_weight=8, n_estimators=200, objective=reg:squarederror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=20, min_child_weight=5, n_estimators=1400, objective=reg:squarederror, tree_method=hist; total time=   0.2s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=14, min_child_weight=4, n_estimators=1400, objective=reg:squarederror, tree_method=approx; total time=   0.2s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=6, min_child_weight=8, n_estimators=200, objective=reg:squarederror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=10, min_child_weight=5, n_estimators=1400, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=10, min_child_weight=5, n_estimators=1400, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=10, min_child_weight=5, n_estimators=1400, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=10, min_child_weight=9, n_estimators=600, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=6, min_child_weight=1, n_estimators=1600, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=20, min_child_weight=2, n_estimators=600, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=20, min_child_weight=2, n_estimators=600, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=20, min_child_weight=5, n_estimators=1400, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=10, min_child_weight=7, n_estimators=1200, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=10, min_child_weight=7, n_estimators=1200, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=10, min_child_weight=10, n_estimators=1800, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=10, min_child_weight=10, n_estimators=1800, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=10, min_child_weight=10, n_estimators=1800, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=10, min_child_weight=9, n_estimators=200, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=10, min_child_weight=9, n_estimators=200, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=10, min_child_weight=9, n_estimators=200, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=18, min_child_weight=5, n_estimators=1600, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=18, min_child_weight=5, n_estimators=1600, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=18, min_child_weight=5, n_estimators=1600, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=14, min_child_weight=1, n_estimators=1200, objective=reg:squarederror, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=10, min_child_weight=9, n_estimators=600, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=14, min_child_weight=4, n_estimators=1400, objective=reg:squarederror, tree_method=approx; total time=   0.2s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=4, min_child_weight=6, n_estimators=2000, objective=reg:squarederror, tree_method=auto; total time=   0.4s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=20, min_child_weight=5, n_estimators=1400, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=12, min_child_weight=4, n_estimators=200, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=12, min_child_weight=4, n_estimators=200, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=12, min_child_weight=4, n_estimators=200, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=8, min_child_weight=4, n_estimators=800, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=12, min_child_weight=10, n_estimators=1800, objective=reg:squarederror, tree_method=exact; total time=   0.5s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=20, min_child_weight=1, n_estimators=1000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=14, min_child_weight=1, n_estimators=1200, objective=reg:squarederror, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=8, min_child_weight=5, n_estimators=1800, objective=reg:squarederror, tree_method=auto; total time=   0.4s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=8, min_child_weight=4, n_estimators=800, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=14, min_child_weight=4, n_estimators=1400, objective=reg:squarederror, tree_method=approx; total time=   0.2s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=20, min_child_weight=4, n_estimators=2000, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=20, min_child_weight=4, n_estimators=2000, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=20, min_child_weight=4, n_estimators=2000, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=6, min_child_weight=7, n_estimators=1200, objective=reg:squarederror, tree_method=auto; total time=   0.2s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=14, min_child_weight=1, n_estimators=1200, objective=reg:squarederror, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=3, n_estimators=1600, objective=reg:squarederror, tree_method=hist; total time=   0.2s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=8, min_child_weight=4, n_estimators=800, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=8, min_child_weight=8, n_estimators=2000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=2, n_estimators=1200, objective=reg:squarederror, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=8, min_child_weight=8, n_estimators=2000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=8, min_child_weight=8, n_estimators=2000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=10, min_child_weight=7, n_estimators=1200, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=10, min_child_weight=7, n_estimators=1200, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=10, min_child_weight=7, n_estimators=1200, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=12, min_child_weight=10, n_estimators=1800, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=12, min_child_weight=10, n_estimators=1800, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=12, min_child_weight=10, n_estimators=1800, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=14, min_child_weight=5, n_estimators=1200, objective=reg:squarederror, tree_method=auto; total time=   0.2s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=20, min_child_weight=9, n_estimators=1400, objective=reg:squarederror, tree_method=hist; total time=   0.2s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=2, min_child_weight=3, n_estimators=1800, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=2, min_child_weight=3, n_estimators=1800, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=2, min_child_weight=3, n_estimators=1800, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=16, min_child_weight=4, n_estimators=400, objective=reg:squarederror, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=4, min_child_weight=6, n_estimators=2000, objective=reg:squarederror, tree_method=auto; total time=   0.3s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=16, min_child_weight=1, n_estimators=400, objective=reg:squarederror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=2, n_estimators=1200, objective=reg:squarederror, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=3, n_estimators=1600, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=16, min_child_weight=1, n_estimators=400, objective=reg:squarederror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=16, min_child_weight=4, n_estimators=400, objective=reg:squarederror, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=6, min_child_weight=7, n_estimators=1200, objective=reg:squarederror, tree_method=auto; total time=   0.3s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=16, min_child_weight=1, n_estimators=400, objective=reg:squarederror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=6, min_child_weight=5, n_estimators=1000, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=6, min_child_weight=5, n_estimators=1000, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=6, min_child_weight=5, n_estimators=1000, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=20, min_child_weight=1, n_estimators=1000, objective=reg:squaredlogerror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=20, min_child_weight=1, n_estimators=1000, objective=reg:squaredlogerror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=20, min_child_weight=1, n_estimators=1000, objective=reg:squaredlogerror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=2, n_estimators=1200, objective=reg:squarederror, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=14, min_child_weight=5, n_estimators=1200, objective=reg:squarederror, tree_method=auto; total time=   0.2s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=8, min_child_weight=2, n_estimators=1400, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=8, min_child_weight=2, n_estimators=1400, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=8, min_child_weight=2, n_estimators=1400, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=8, min_child_weight=4, n_estimators=800, objective=reg:squaredlogerror, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=8, min_child_weight=4, n_estimators=800, objective=reg:squaredlogerror, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=8, min_child_weight=4, n_estimators=800, objective=reg:squaredlogerror, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=10, min_child_weight=7, n_estimators=1200, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=18, min_child_weight=5, n_estimators=200, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=3, n_estimators=1600, objective=reg:squarederror, tree_method=hist; total time=   0.2s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=16, min_child_weight=4, n_estimators=400, objective=reg:squarederror, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=2, min_child_weight=6, n_estimators=1000, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=2, min_child_weight=6, n_estimators=1000, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=2, min_child_weight=6, n_estimators=1000, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=8, min_child_weight=7, n_estimators=1600, objective=reg:squaredlogerror, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=18, min_child_weight=5, n_estimators=200, objective=reg:squarederror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=14, min_child_weight=10, n_estimators=600, objective=reg:squarederror, tree_method=auto; total time=   0.3s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=18, min_child_weight=8, n_estimators=600, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=4, min_child_weight=6, n_estimators=2000, objective=reg:squarederror, tree_method=auto; total time=   0.3s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=16, min_child_weight=5, n_estimators=1400, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=16, min_child_weight=5, n_estimators=1400, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=16, min_child_weight=5, n_estimators=1400, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=20, min_child_weight=5, n_estimators=1000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=20, min_child_weight=5, n_estimators=1000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=20, min_child_weight=5, n_estimators=1000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=18, min_child_weight=5, n_estimators=200, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=14, min_child_weight=4, n_estimators=200, objective=reg:squaredlogerror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=14, min_child_weight=8, n_estimators=200, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=14, min_child_weight=4, n_estimators=200, objective=reg:squaredlogerror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=18, min_child_weight=5, n_estimators=600, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=18, min_child_weight=5, n_estimators=600, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=18, min_child_weight=5, n_estimators=600, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=16, min_child_weight=6, n_estimators=2000, objective=reg:squaredlogerror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=14, min_child_weight=5, n_estimators=1200, objective=reg:squarederror, tree_method=auto; total time=   0.2s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=16, min_child_weight=6, n_estimators=2000, objective=reg:squaredlogerror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=16, min_child_weight=6, n_estimators=2000, objective=reg:squaredlogerror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=12, min_child_weight=9, n_estimators=200, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=8, min_child_weight=5, n_estimators=1000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=12, min_child_weight=4, n_estimators=1000, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=12, min_child_weight=4, n_estimators=1000, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=8, min_child_weight=5, n_estimators=1000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=12, min_child_weight=4, n_estimators=1000, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=8, min_child_weight=5, n_estimators=1000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=14, min_child_weight=5, n_estimators=1200, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=18, min_child_weight=6, n_estimators=1000, objective=reg:squaredlogerror, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=14, min_child_weight=5, n_estimators=1200, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=18, min_child_weight=6, n_estimators=1000, objective=reg:squaredlogerror, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=18, min_child_weight=6, n_estimators=1000, objective=reg:squaredlogerror, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=14, min_child_weight=5, n_estimators=1200, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=2, min_child_weight=1, n_estimators=400, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=12, min_child_weight=9, n_estimators=200, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=2, min_child_weight=1, n_estimators=400, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=2, min_child_weight=1, n_estimators=400, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=4, min_child_weight=10, n_estimators=1400, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=4, min_child_weight=10, n_estimators=1400, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=12, min_child_weight=9, n_estimators=200, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=4, min_child_weight=10, n_estimators=1400, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=4, min_child_weight=1, n_estimators=1000, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=14, min_child_weight=4, n_estimators=1800, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=4, min_child_weight=1, n_estimators=1000, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=6, min_child_weight=7, n_estimators=1200, objective=reg:squarederror, tree_method=auto; total time=   0.2s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=14, min_child_weight=4, n_estimators=1800, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=4, min_child_weight=1, n_estimators=1000, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=14, min_child_weight=4, n_estimators=1800, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=8, min_child_weight=3, n_estimators=2000, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=8, min_child_weight=3, n_estimators=2000, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=8, min_child_weight=3, n_estimators=2000, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=14, min_child_weight=3, n_estimators=600, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=18, min_child_weight=8, n_estimators=600, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=14, min_child_weight=9, n_estimators=600, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=14, min_child_weight=9, n_estimators=600, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=14, min_child_weight=9, n_estimators=600, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=14, min_child_weight=10, n_estimators=600, objective=reg:squarederror, tree_method=auto; total time=   0.2s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=12, min_child_weight=8, n_estimators=200, objective=reg:squarederror, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=6, min_child_weight=8, n_estimators=600, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=14, min_child_weight=3, n_estimators=600, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=12, min_child_weight=8, n_estimators=200, objective=reg:squarederror, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=10, min_child_weight=6, n_estimators=1400, objective=reg:squarederror, tree_method=approx; total time=   0.2s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=12, min_child_weight=8, n_estimators=200, objective=reg:squarederror, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=8, min_child_weight=2, n_estimators=1800, objective=reg:squarederror, tree_method=exact; total time=   0.2s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=10, min_child_weight=7, n_estimators=1200, objective=reg:squarederror, tree_method=auto; total time=   0.4s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=6, min_child_weight=8, n_estimators=600, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=14, min_child_weight=3, n_estimators=600, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=12, min_child_weight=4, n_estimators=600, objective=reg:squaredlogerror, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=12, min_child_weight=4, n_estimators=600, objective=reg:squaredlogerror, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=12, min_child_weight=4, n_estimators=600, objective=reg:squaredlogerror, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=14, min_child_weight=10, n_estimators=600, objective=reg:squarederror, tree_method=auto; total time=   0.2s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=4, min_child_weight=2, n_estimators=2000, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=2, min_child_weight=5, n_estimators=1000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=2, min_child_weight=5, n_estimators=1000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=2, min_child_weight=5, n_estimators=1000, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=4, min_child_weight=2, n_estimators=2000, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=20, min_child_weight=9, n_estimators=1400, objective=reg:squarederror, tree_method=hist; total time=   0.3s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=4, min_child_weight=2, n_estimators=2000, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=18, min_child_weight=3, n_estimators=2000, objective=reg:squaredlogerror, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=18, min_child_weight=3, n_estimators=2000, objective=reg:squaredlogerror, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=18, min_child_weight=3, n_estimators=2000, objective=reg:squaredlogerror, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=2, min_child_weight=5, n_estimators=1000, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=2, min_child_weight=5, n_estimators=1000, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=2, min_child_weight=5, n_estimators=1000, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=4, min_child_weight=8, n_estimators=800, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=6, min_child_weight=2, n_estimators=1000, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=6, min_child_weight=8, n_estimators=600, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=10, min_child_weight=6, n_estimators=1400, objective=reg:squarederror, tree_method=approx; total time=   0.2s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=8, min_child_weight=2, n_estimators=1800, objective=reg:squarederror, tree_method=exact; total time=   0.2s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=20, min_child_weight=10, n_estimators=1000, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=4, min_child_weight=8, n_estimators=800, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=6, min_child_weight=2, n_estimators=1000, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=20, min_child_weight=10, n_estimators=1000, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=20, min_child_weight=10, n_estimators=1000, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=16, min_child_weight=10, n_estimators=2000, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=16, min_child_weight=10, n_estimators=2000, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=16, min_child_weight=10, n_estimators=2000, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=4, min_child_weight=9, n_estimators=1200, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=4, min_child_weight=9, n_estimators=1200, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=4, min_child_weight=9, n_estimators=1200, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=6, min_child_weight=2, n_estimators=1000, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=18, min_child_weight=1, n_estimators=200, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=18, min_child_weight=1, n_estimators=200, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=18, min_child_weight=1, n_estimators=200, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=20, min_child_weight=9, n_estimators=1400, objective=reg:squarederror, tree_method=hist; total time=   0.3s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=3, n_estimators=1800, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=10, min_child_weight=6, n_estimators=1400, objective=reg:squarederror, tree_method=approx; total time=   0.2s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=3, n_estimators=1800, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=8, min_child_weight=5, n_estimators=400, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=2, min_child_weight=3, n_estimators=1800, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=8, min_child_weight=5, n_estimators=400, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=8, min_child_weight=1, n_estimators=1400, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=8, min_child_weight=5, n_estimators=400, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=8, min_child_weight=1, n_estimators=1400, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=8, min_child_weight=1, n_estimators=1400, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=18, min_child_weight=2, n_estimators=1400, objective=reg:squarederror, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=4, min_child_weight=7, n_estimators=600, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=4, min_child_weight=7, n_estimators=600, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=12, min_child_weight=8, n_estimators=1200, objective=reg:squarederror, tree_method=exact; total time=   0.3s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=4, min_child_weight=8, n_estimators=800, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=4, min_child_weight=7, n_estimators=2000, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=10, min_child_weight=10, n_estimators=1200, objective=reg:squaredlogerror, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=10, min_child_weight=10, n_estimators=1200, objective=reg:squaredlogerror, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=4, min_child_weight=7, n_estimators=600, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=4, min_child_weight=7, n_estimators=2000, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=10, min_child_weight=10, n_estimators=1200, objective=reg:squaredlogerror, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=14, min_child_weight=4, n_estimators=200, objective=reg:squaredlogerror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=14, min_child_weight=8, n_estimators=800, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=4, min_child_weight=7, n_estimators=2000, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=14, min_child_weight=8, n_estimators=800, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=4, min_child_weight=6, n_estimators=200, objective=reg:squarederror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=2, min_child_weight=9, n_estimators=400, objective=reg:squaredlogerror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=6, min_child_weight=10, n_estimators=1200, objective=reg:squaredlogerror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=2, min_child_weight=9, n_estimators=400, objective=reg:squaredlogerror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=6, min_child_weight=10, n_estimators=1200, objective=reg:squaredlogerror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=6, min_child_weight=10, n_estimators=1200, objective=reg:squaredlogerror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=6, min_child_weight=8, n_estimators=1800, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=6, min_child_weight=8, n_estimators=1800, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=2, min_child_weight=9, n_estimators=400, objective=reg:squaredlogerror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=6, min_child_weight=8, n_estimators=1800, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=18, min_child_weight=3, n_estimators=800, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=18, min_child_weight=3, n_estimators=800, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=18, min_child_weight=3, n_estimators=800, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=12, min_child_weight=3, n_estimators=1800, objective=reg:squarederror, tree_method=exact; total time=   0.2s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=4, min_child_weight=6, n_estimators=200, objective=reg:squarederror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=10, min_child_weight=7, n_estimators=1200, objective=reg:squarederror, tree_method=auto; total time=   0.4s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=14, min_child_weight=8, n_estimators=200, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=4, min_child_weight=6, n_estimators=200, objective=reg:squarederror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=18, min_child_weight=2, n_estimators=1400, objective=reg:squarederror, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=12, min_child_weight=1, n_estimators=1200, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=14, min_child_weight=8, n_estimators=200, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=4, min_child_weight=6, n_estimators=1600, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=18, min_child_weight=2, n_estimators=1400, objective=reg:squarederror, tree_method=approx; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=18, min_child_weight=8, n_estimators=600, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=12, min_child_weight=1, n_estimators=1200, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=4, min_child_weight=6, n_estimators=1600, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=4, min_child_weight=8, n_estimators=200, objective=reg:squarederror, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=4, min_child_weight=8, n_estimators=200, objective=reg:squarederror, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=4, min_child_weight=8, n_estimators=200, objective=reg:squarederror, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=4, min_child_weight=10, n_estimators=1000, objective=reg:squaredlogerror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=4, min_child_weight=10, n_estimators=1000, objective=reg:squaredlogerror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=4, min_child_weight=10, n_estimators=1000, objective=reg:squaredlogerror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=4, min_child_weight=6, n_estimators=1600, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=12, min_child_weight=1, n_estimators=1200, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=10, min_child_weight=7, n_estimators=1200, objective=reg:squarederror, tree_method=auto; total time=   0.3s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=16, min_child_weight=5, n_estimators=600, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=16, min_child_weight=5, n_estimators=600, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=16, min_child_weight=5, n_estimators=1000, objective=reg:squarederror, tree_method=exact; total time=   0.2s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=14, min_child_weight=5, n_estimators=1200, objective=reg:squarederror, tree_method=auto; total time=   0.4s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=12, min_child_weight=3, n_estimators=1800, objective=reg:squarederror, tree_method=exact; total time=   0.4s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=16, min_child_weight=5, n_estimators=1000, objective=reg:squarederror, tree_method=exact; total time=   0.2s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=16, min_child_weight=5, n_estimators=1000, objective=reg:squarederror, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=6, min_child_weight=5, n_estimators=600, objective=reg:squarederror, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=6, min_child_weight=5, n_estimators=600, objective=reg:squarederror, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=6, min_child_weight=5, n_estimators=600, objective=reg:squarederror, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=12, min_child_weight=9, n_estimators=800, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=16, min_child_weight=8, n_estimators=1600, objective=reg:squarederror, tree_method=auto; total time=   0.3s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=12, min_child_weight=8, n_estimators=1200, objective=reg:squarederror, tree_method=exact; total time=   0.4s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=12, min_child_weight=3, n_estimators=1800, objective=reg:squarederror, tree_method=exact; total time=   0.2s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=5, n_estimators=600, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=5, n_estimators=600, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=12, min_child_weight=9, n_estimators=800, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=14, min_child_weight=5, n_estimators=600, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=12, min_child_weight=9, n_estimators=800, objective=reg:squarederror, tree_method=hist; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=16, min_child_weight=1, n_estimators=800, objective=reg:squaredlogerror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=16, min_child_weight=1, n_estimators=800, objective=reg:squaredlogerror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=16, min_child_weight=1, n_estimators=800, objective=reg:squaredlogerror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=20, min_child_weight=3, n_estimators=1800, objective=reg:squarederror, tree_method=approx; total time=   0.2s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=20, min_child_weight=3, n_estimators=1800, objective=reg:squarederror, tree_method=approx; total time=   0.3s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=8, min_child_weight=2, n_estimators=1800, objective=reg:squarederror, tree_method=exact; total time=   0.2s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=10, min_child_weight=4, n_estimators=1600, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=10, min_child_weight=4, n_estimators=1600, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=10, min_child_weight=4, n_estimators=1600, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=14, min_child_weight=5, n_estimators=1200, objective=reg:squarederror, tree_method=auto; total time=   0.5s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=20, min_child_weight=3, n_estimators=1800, objective=reg:squarederror, tree_method=approx; total time=   0.3s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=16, min_child_weight=3, n_estimators=1400, objective=reg:squarederror, tree_method=auto; total time=   0.3s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=16, min_child_weight=3, n_estimators=1400, objective=reg:squarederror, tree_method=auto; total time=   0.3s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=6, min_child_weight=8, n_estimators=600, objective=reg:squaredlogerror, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=6, min_child_weight=8, n_estimators=600, objective=reg:squaredlogerror, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=6, min_child_weight=8, n_estimators=600, objective=reg:squaredlogerror, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=12, min_child_weight=8, n_estimators=1200, objective=reg:squarederror, tree_method=exact; total time=   0.4s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=14, min_child_weight=4, n_estimators=1000, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=14, min_child_weight=4, n_estimators=1000, objective=reg:squarederror, tree_method=auto; total time=   0.2s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=2, min_child_weight=9, n_estimators=2000, objective=reg:squaredlogerror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=2, min_child_weight=9, n_estimators=2000, objective=reg:squaredlogerror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=2, min_child_weight=9, n_estimators=2000, objective=reg:squaredlogerror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=10, min_child_weight=8, n_estimators=200, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=16, min_child_weight=3, n_estimators=1400, objective=reg:squarederror, tree_method=auto; total time=   0.2s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=10, min_child_weight=8, n_estimators=200, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=10, min_child_weight=8, n_estimators=200, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=12, min_child_weight=7, n_estimators=600, objective=reg:squaredlogerror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=16, min_child_weight=8, n_estimators=1600, objective=reg:squarederror, tree_method=auto; total time=   0.4s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=12, min_child_weight=7, n_estimators=600, objective=reg:squaredlogerror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=12, min_child_weight=7, n_estimators=600, objective=reg:squaredlogerror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=12, min_child_weight=5, n_estimators=400, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=12, min_child_weight=5, n_estimators=400, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=12, min_child_weight=5, n_estimators=400, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=14, min_child_weight=4, n_estimators=1000, objective=reg:squarederror, tree_method=auto; total time=   0.2s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=14, min_child_weight=5, n_estimators=1800, objective=reg:squarederror, tree_method=exact; total time=   0.2s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=14, min_child_weight=5, n_estimators=1800, objective=reg:squarederror, tree_method=exact; total time=   0.2s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=14, min_child_weight=5, n_estimators=1200, objective=reg:squarederror, tree_method=auto; total time=   0.4s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=16, min_child_weight=9, n_estimators=1800, objective=reg:squarederror, tree_method=exact; total time=   0.2s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=20, min_child_weight=9, n_estimators=1800, objective=reg:squaredlogerror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=20, min_child_weight=9, n_estimators=1800, objective=reg:squaredlogerror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=20, min_child_weight=9, n_estimators=1800, objective=reg:squaredlogerror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=16, min_child_weight=9, n_estimators=1800, objective=reg:squarederror, tree_method=exact; total time=   0.3s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=16, min_child_weight=9, n_estimators=1800, objective=reg:squarederror, tree_method=exact; total time=   0.3s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=7, n_estimators=200, objective=reg:squarederror, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=7, n_estimators=200, objective=reg:squarederror, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=8, min_child_weight=8, n_estimators=1200, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=8, min_child_weight=8, n_estimators=1200, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=16, min_child_weight=8, n_estimators=1600, objective=reg:squarederror, tree_method=auto; total time=   0.3s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=8, min_child_weight=8, n_estimators=1200, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=18, min_child_weight=1, n_estimators=1800, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=18, min_child_weight=1, n_estimators=1800, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=18, min_child_weight=1, n_estimators=1800, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=12, min_child_weight=2, n_estimators=1400, objective=reg:squaredlogerror, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=14, min_child_weight=8, n_estimators=800, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=12, min_child_weight=2, n_estimators=1400, objective=reg:squaredlogerror, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=12, min_child_weight=2, n_estimators=1400, objective=reg:squaredlogerror, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=7, n_estimators=200, objective=reg:squarederror, tree_method=exact; total time=   0.1s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=2, min_child_weight=8, n_estimators=1200, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=2, min_child_weight=8, n_estimators=1200, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=2, min_child_weight=8, n_estimators=1200, objective=reg:squaredlogerror, tree_method=auto; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=14, min_child_weight=5, n_estimators=1800, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=14, min_child_weight=5, n_estimators=1800, objective=reg:squarederror, tree_method=exact; total time=   0.2s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=14, min_child_weight=5, n_estimators=1800, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=14, min_child_weight=5, n_estimators=1800, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=6, min_child_weight=3, n_estimators=600, objective=reg:squaredlogerror, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=6, min_child_weight=3, n_estimators=600, objective=reg:squaredlogerror, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=6, min_child_weight=3, n_estimators=600, objective=reg:squaredlogerror, tree_method=approx; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=9, n_estimators=1600, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=9, n_estimators=1600, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=20, min_child_weight=9, n_estimators=1600, objective=reg:squaredlogerror, tree_method=hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=6, min_child_weight=9, n_estimators=200, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=6, min_child_weight=9, n_estimators=200, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=10, min_child_weight=4, n_estimators=1000, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.4, gamma=0, max_depth=6, min_child_weight=9, n_estimators=200, objective=reg:squarederror, tree_method=gpu_hist; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=10, min_child_weight=4, n_estimators=1000, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.1, gamma=0, max_depth=10, min_child_weight=4, n_estimators=1000, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=4, min_child_weight=9, n_estimators=400, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=4, min_child_weight=9, n_estimators=400, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.6, gamma=0, max_depth=4, min_child_weight=9, n_estimators=400, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=14, min_child_weight=7, n_estimators=1000, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=14, min_child_weight=7, n_estimators=1000, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=14, min_child_weight=7, n_estimators=1000, objective=reg:squaredlogerror, tree_method=exact; total time=   0.0s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=2, min_child_weight=5, n_estimators=1800, objective=reg:squarederror, tree_method=auto; total time=   0.2s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=2, min_child_weight=5, n_estimators=1800, objective=reg:squarederror, tree_method=auto; total time=   0.2s\n",
      "[CV] END eta=0.5, gamma=0, max_depth=2, min_child_weight=5, n_estimators=1800, objective=reg:squarederror, tree_method=auto; total time=   0.2s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=6, min_child_weight=8, n_estimators=600, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=6, min_child_weight=8, n_estimators=600, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.30000000000000004, gamma=0, max_depth=6, min_child_weight=8, n_estimators=600, objective=reg:squarederror, tree_method=auto; total time=   0.1s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=16, min_child_weight=7, n_estimators=1400, objective=reg:squarederror, tree_method=exact; total time=   0.3s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=16, min_child_weight=7, n_estimators=1400, objective=reg:squarederror, tree_method=exact; total time=   0.3s\n",
      "[CV] END eta=0.2, gamma=0, max_depth=16, min_child_weight=7, n_estimators=1400, objective=reg:squarederror, tree_method=exact; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "393 fits failed out of a total of 600.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:53] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/objective/regression_obj.cu:148: label must be greater than -1 for rmsle so that log(label + 1) can be valid.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x0000000130005bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x000000013016c244 xgboost::obj::RegLossObj<xgboost::obj::SquaredLogError>::GetGradient(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, int, xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float>>*) + 580\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x00000001301066ac xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 608\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x000000013001f418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (4) 5   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (5) 6   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (6) 7   _ctypes.cpython-38-darwin.so        0x00000001010ebde4 _ctypes_callproc + 1236\n",
      "  [bt] (7) 8   _ctypes.cpython-38-darwin.so        0x00000001010e4d24 PyCFuncPtr_call + 1172\n",
      "  [bt] (8) 9   libpython3.8.dylib                  0x0000000100417fc8 _PyObject_MakeTpCall + 372\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:53] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/objective/regression_obj.cu:148: label must be greater than -1 for rmsle so that log(label + 1) can be valid.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x00000001373e5bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x000000013754c244 xgboost::obj::RegLossObj<xgboost::obj::SquaredLogError>::GetGradient(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, int, xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float>>*) + 580\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x00000001374e66ac xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 608\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x00000001373ff418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (4) 5   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (5) 6   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (6) 7   _ctypes.cpython-38-darwin.so        0x00000001047fbde4 _ctypes_callproc + 1236\n",
      "  [bt] (7) 8   _ctypes.cpython-38-darwin.so        0x00000001047f4d24 PyCFuncPtr_call + 1172\n",
      "  [bt] (8) 9   libpython3.8.dylib                  0x000000010321bfc8 _PyObject_MakeTpCall + 372\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:53] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/objective/regression_obj.cu:148: label must be greater than -1 for rmsle so that log(label + 1) can be valid.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x000000012dbe5bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x000000012dd4c244 xgboost::obj::RegLossObj<xgboost::obj::SquaredLogError>::GetGradient(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, int, xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float>>*) + 580\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x000000012dce66ac xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 608\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x000000012dbff418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (4) 5   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (5) 6   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (6) 7   _ctypes.cpython-38-darwin.so        0x000000010492fde4 _ctypes_callproc + 1236\n",
      "  [bt] (7) 8   _ctypes.cpython-38-darwin.so        0x0000000104928d24 PyCFuncPtr_call + 1172\n",
      "  [bt] (8) 9   libpython3.8.dylib                  0x0000000103333fc8 _PyObject_MakeTpCall + 372\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:53] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/objective/regression_obj.cu:148: label must be greater than -1 for rmsle so that log(label + 1) can be valid.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x0000000128005bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x000000012816c244 xgboost::obj::RegLossObj<xgboost::obj::SquaredLogError>::GetGradient(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, int, xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float>>*) + 580\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x00000001281066ac xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 608\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x000000012801f418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (4) 5   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (5) 6   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (6) 7   _ctypes.cpython-38-darwin.so        0x00000001014f3de4 _ctypes_callproc + 1236\n",
      "  [bt] (7) 8   _ctypes.cpython-38-darwin.so        0x00000001014ecd24 PyCFuncPtr_call + 1172\n",
      "  [bt] (8) 9   libpython3.8.dylib                  0x000000010081ffc8 _PyObject_MakeTpCall + 372\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:53] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/gbm/../common/common.h:239: XGBoost version not compiled with GPU support.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x0000000130005bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x00000001300eb21c xgboost::gbm::GBTree::ConfigureUpdaters() + 476\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x00000001300e6374 xgboost::gbm::GBTree::Configure(std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>>> const&) + 952\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x00000001301061b4 xgboost::LearnerConfiguration::Configure() + 1124\n",
      "  [bt] (4) 5   libxgboost.dylib                    0x00000001301064cc xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 128\n",
      "  [bt] (5) 6   libxgboost.dylib                    0x000000013001f418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (6) 7   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (7) 8   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (8) 9   _ctypes.cpython-38-darwin.so        0x00000001010ebde4 _ctypes_callproc + 1236\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:53] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/gbm/../common/common.h:239: XGBoost version not compiled with GPU support.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x000000012dbe5bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x000000012dccb21c xgboost::gbm::GBTree::ConfigureUpdaters() + 476\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x000000012dcc6374 xgboost::gbm::GBTree::Configure(std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>>> const&) + 952\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x000000012dce61b4 xgboost::LearnerConfiguration::Configure() + 1124\n",
      "  [bt] (4) 5   libxgboost.dylib                    0x000000012dce64cc xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 128\n",
      "  [bt] (5) 6   libxgboost.dylib                    0x000000012dbff418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (6) 7   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (7) 8   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (8) 9   _ctypes.cpython-38-darwin.so        0x000000010492fde4 _ctypes_callproc + 1236\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:53] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/gbm/../common/common.h:239: XGBoost version not compiled with GPU support.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x00000001373e5bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x00000001374cb21c xgboost::gbm::GBTree::ConfigureUpdaters() + 476\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x00000001374c6374 xgboost::gbm::GBTree::Configure(std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>>> const&) + 952\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x00000001374e61b4 xgboost::LearnerConfiguration::Configure() + 1124\n",
      "  [bt] (4) 5   libxgboost.dylib                    0x00000001374e64cc xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 128\n",
      "  [bt] (5) 6   libxgboost.dylib                    0x00000001373ff418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (6) 7   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (7) 8   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (8) 9   _ctypes.cpython-38-darwin.so        0x00000001047fbde4 _ctypes_callproc + 1236\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:53] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/gbm/../common/common.h:239: XGBoost version not compiled with GPU support.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x0000000128005bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x00000001280eb21c xgboost::gbm::GBTree::ConfigureUpdaters() + 476\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x00000001280e6374 xgboost::gbm::GBTree::Configure(std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>>> const&) + 952\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x00000001281061b4 xgboost::LearnerConfiguration::Configure() + 1124\n",
      "  [bt] (4) 5   libxgboost.dylib                    0x00000001281064cc xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 128\n",
      "  [bt] (5) 6   libxgboost.dylib                    0x000000012801f418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (6) 7   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (7) 8   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (8) 9   _ctypes.cpython-38-darwin.so        0x00000001014f3de4 _ctypes_callproc + 1236\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:53] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/gbm/../common/common.h:239: XGBoost version not compiled with GPU support.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x0000000122805bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x00000001228eb21c xgboost::gbm::GBTree::ConfigureUpdaters() + 476\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x00000001228e6374 xgboost::gbm::GBTree::Configure(std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>>> const&) + 952\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x00000001229061b4 xgboost::LearnerConfiguration::Configure() + 1124\n",
      "  [bt] (4) 5   libxgboost.dylib                    0x00000001229064cc xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 128\n",
      "  [bt] (5) 6   libxgboost.dylib                    0x000000012281f418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (6) 7   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (7) 8   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (8) 9   _ctypes.cpython-38-darwin.so        0x00000001037fbde4 _ctypes_callproc + 1236\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:53] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/objective/regression_obj.cu:148: label must be greater than -1 for rmsle so that log(label + 1) can be valid.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x0000000123325bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x000000012348c244 xgboost::obj::RegLossObj<xgboost::obj::SquaredLogError>::GetGradient(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, int, xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float>>*) + 580\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x00000001234266ac xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 608\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x000000012333f418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (4) 5   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (5) 6   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (6) 7   _ctypes.cpython-38-darwin.so        0x000000010595bde4 _ctypes_callproc + 1236\n",
      "  [bt] (7) 8   _ctypes.cpython-38-darwin.so        0x0000000105954d24 PyCFuncPtr_call + 1172\n",
      "  [bt] (8) 9   libpython3.8.dylib                  0x0000000104c87fc8 _PyObject_MakeTpCall + 372\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:53] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/objective/regression_obj.cu:148: label must be greater than -1 for rmsle so that log(label + 1) can be valid.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x0000000122805bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x000000012296c244 xgboost::obj::RegLossObj<xgboost::obj::SquaredLogError>::GetGradient(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, int, xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float>>*) + 580\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x00000001229066ac xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 608\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x000000012281f418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (4) 5   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (5) 6   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (6) 7   _ctypes.cpython-38-darwin.so        0x00000001037fbde4 _ctypes_callproc + 1236\n",
      "  [bt] (7) 8   _ctypes.cpython-38-darwin.so        0x00000001037f4d24 PyCFuncPtr_call + 1172\n",
      "  [bt] (8) 9   libpython3.8.dylib                  0x000000010081bfc8 _PyObject_MakeTpCall + 372\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "16 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:54] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/objective/regression_obj.cu:148: label must be greater than -1 for rmsle so that log(label + 1) can be valid.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x0000000122805bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x000000012296c244 xgboost::obj::RegLossObj<xgboost::obj::SquaredLogError>::GetGradient(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, int, xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float>>*) + 580\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x00000001229066ac xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 608\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x000000012281f418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (4) 5   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (5) 6   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (6) 7   _ctypes.cpython-38-darwin.so        0x00000001037fbde4 _ctypes_callproc + 1236\n",
      "  [bt] (7) 8   _ctypes.cpython-38-darwin.so        0x00000001037f4d24 PyCFuncPtr_call + 1172\n",
      "  [bt] (8) 9   libpython3.8.dylib                  0x000000010081bfc8 _PyObject_MakeTpCall + 372\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:53] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/objective/regression_obj.cu:148: label must be greater than -1 for rmsle so that log(label + 1) can be valid.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x00000001371e5bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x000000013734c244 xgboost::obj::RegLossObj<xgboost::obj::SquaredLogError>::GetGradient(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, int, xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float>>*) + 580\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x00000001372e66ac xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 608\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x00000001371ff418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (4) 5   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (5) 6   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (6) 7   _ctypes.cpython-38-darwin.so        0x0000000106057de4 _ctypes_callproc + 1236\n",
      "  [bt] (7) 8   _ctypes.cpython-38-darwin.so        0x0000000106050d24 PyCFuncPtr_call + 1172\n",
      "  [bt] (8) 9   libpython3.8.dylib                  0x0000000105383fc8 _PyObject_MakeTpCall + 372\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "13 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:55] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/objective/regression_obj.cu:148: label must be greater than -1 for rmsle so that log(label + 1) can be valid.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x000000012dbe5bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x000000012dd4c244 xgboost::obj::RegLossObj<xgboost::obj::SquaredLogError>::GetGradient(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, int, xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float>>*) + 580\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x000000012dce66ac xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 608\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x000000012dbff418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (4) 5   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (5) 6   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (6) 7   _ctypes.cpython-38-darwin.so        0x000000010492fde4 _ctypes_callproc + 1236\n",
      "  [bt] (7) 8   _ctypes.cpython-38-darwin.so        0x0000000104928d24 PyCFuncPtr_call + 1172\n",
      "  [bt] (8) 9   libpython3.8.dylib                  0x0000000103333fc8 _PyObject_MakeTpCall + 372\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:54] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/objective/regression_obj.cu:148: label must be greater than -1 for rmsle so that log(label + 1) can be valid.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x0000000130005bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x000000013016c244 xgboost::obj::RegLossObj<xgboost::obj::SquaredLogError>::GetGradient(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, int, xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float>>*) + 580\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x00000001301066ac xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 608\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x000000013001f418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (4) 5   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (5) 6   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (6) 7   _ctypes.cpython-38-darwin.so        0x00000001010ebde4 _ctypes_callproc + 1236\n",
      "  [bt] (7) 8   _ctypes.cpython-38-darwin.so        0x00000001010e4d24 PyCFuncPtr_call + 1172\n",
      "  [bt] (8) 9   libpython3.8.dylib                  0x0000000100417fc8 _PyObject_MakeTpCall + 372\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:53] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/objective/regression_obj.cu:148: label must be greater than -1 for rmsle so that log(label + 1) can be valid.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x000000012d005bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x000000012d16c244 xgboost::obj::RegLossObj<xgboost::obj::SquaredLogError>::GetGradient(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, int, xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float>>*) + 580\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x000000012d1066ac xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 608\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x000000012d01f418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (4) 5   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (5) 6   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (6) 7   _ctypes.cpython-38-darwin.so        0x0000000105987de4 _ctypes_callproc + 1236\n",
      "  [bt] (7) 8   _ctypes.cpython-38-darwin.so        0x0000000105980d24 PyCFuncPtr_call + 1172\n",
      "  [bt] (8) 9   libpython3.8.dylib                  0x0000000104cb3fc8 _PyObject_MakeTpCall + 372\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:54] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/objective/regression_obj.cu:148: label must be greater than -1 for rmsle so that log(label + 1) can be valid.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x000000012d005bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x000000012d16c244 xgboost::obj::RegLossObj<xgboost::obj::SquaredLogError>::GetGradient(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, int, xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float>>*) + 580\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x000000012d1066ac xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 608\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x000000012d01f418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (4) 5   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (5) 6   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (6) 7   _ctypes.cpython-38-darwin.so        0x0000000105987de4 _ctypes_callproc + 1236\n",
      "  [bt] (7) 8   _ctypes.cpython-38-darwin.so        0x0000000105980d24 PyCFuncPtr_call + 1172\n",
      "  [bt] (8) 9   libpython3.8.dylib                  0x0000000104cb3fc8 _PyObject_MakeTpCall + 372\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "16 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:54] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/objective/regression_obj.cu:148: label must be greater than -1 for rmsle so that log(label + 1) can be valid.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x0000000128005bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x000000012816c244 xgboost::obj::RegLossObj<xgboost::obj::SquaredLogError>::GetGradient(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, int, xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float>>*) + 580\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x00000001281066ac xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 608\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x000000012801f418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (4) 5   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (5) 6   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (6) 7   _ctypes.cpython-38-darwin.so        0x00000001014f3de4 _ctypes_callproc + 1236\n",
      "  [bt] (7) 8   _ctypes.cpython-38-darwin.so        0x00000001014ecd24 PyCFuncPtr_call + 1172\n",
      "  [bt] (8) 9   libpython3.8.dylib                  0x000000010081ffc8 _PyObject_MakeTpCall + 372\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:54] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/objective/regression_obj.cu:148: label must be greater than -1 for rmsle so that log(label + 1) can be valid.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x00000001371e5bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x000000013734c244 xgboost::obj::RegLossObj<xgboost::obj::SquaredLogError>::GetGradient(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, int, xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float>>*) + 580\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x00000001372e66ac xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 608\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x00000001371ff418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (4) 5   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (5) 6   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (6) 7   _ctypes.cpython-38-darwin.so        0x0000000106057de4 _ctypes_callproc + 1236\n",
      "  [bt] (7) 8   _ctypes.cpython-38-darwin.so        0x0000000106050d24 PyCFuncPtr_call + 1172\n",
      "  [bt] (8) 9   libpython3.8.dylib                  0x0000000105383fc8 _PyObject_MakeTpCall + 372\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:54] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/gbm/../common/common.h:239: XGBoost version not compiled with GPU support.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x0000000128005bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x00000001280eb21c xgboost::gbm::GBTree::ConfigureUpdaters() + 476\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x00000001280e6374 xgboost::gbm::GBTree::Configure(std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>>> const&) + 952\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x00000001281061b4 xgboost::LearnerConfiguration::Configure() + 1124\n",
      "  [bt] (4) 5   libxgboost.dylib                    0x00000001281064cc xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 128\n",
      "  [bt] (5) 6   libxgboost.dylib                    0x000000012801f418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (6) 7   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (7) 8   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (8) 9   _ctypes.cpython-38-darwin.so        0x00000001014f3de4 _ctypes_callproc + 1236\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "16 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:54] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/gbm/../common/common.h:239: XGBoost version not compiled with GPU support.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x0000000123325bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x000000012340b21c xgboost::gbm::GBTree::ConfigureUpdaters() + 476\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x0000000123406374 xgboost::gbm::GBTree::Configure(std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>>> const&) + 952\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x00000001234261b4 xgboost::LearnerConfiguration::Configure() + 1124\n",
      "  [bt] (4) 5   libxgboost.dylib                    0x00000001234264cc xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 128\n",
      "  [bt] (5) 6   libxgboost.dylib                    0x000000012333f418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (6) 7   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (7) 8   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (8) 9   _ctypes.cpython-38-darwin.so        0x000000010595bde4 _ctypes_callproc + 1236\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "28 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:54] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/objective/regression_obj.cu:148: label must be greater than -1 for rmsle so that log(label + 1) can be valid.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x0000000123325bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x000000012348c244 xgboost::obj::RegLossObj<xgboost::obj::SquaredLogError>::GetGradient(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, int, xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float>>*) + 580\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x00000001234266ac xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 608\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x000000012333f418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (4) 5   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (5) 6   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (6) 7   _ctypes.cpython-38-darwin.so        0x000000010595bde4 _ctypes_callproc + 1236\n",
      "  [bt] (7) 8   _ctypes.cpython-38-darwin.so        0x0000000105954d24 PyCFuncPtr_call + 1172\n",
      "  [bt] (8) 9   libpython3.8.dylib                  0x0000000104c87fc8 _PyObject_MakeTpCall + 372\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:54] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/gbm/../common/common.h:239: XGBoost version not compiled with GPU support.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x0000000122805bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x00000001228eb21c xgboost::gbm::GBTree::ConfigureUpdaters() + 476\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x00000001228e6374 xgboost::gbm::GBTree::Configure(std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>>> const&) + 952\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x00000001229061b4 xgboost::LearnerConfiguration::Configure() + 1124\n",
      "  [bt] (4) 5   libxgboost.dylib                    0x00000001229064cc xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 128\n",
      "  [bt] (5) 6   libxgboost.dylib                    0x000000012281f418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (6) 7   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (7) 8   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (8) 9   _ctypes.cpython-38-darwin.so        0x00000001037fbde4 _ctypes_callproc + 1236\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:54] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/gbm/../common/common.h:239: XGBoost version not compiled with GPU support.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x00000001371e5bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x00000001372cb21c xgboost::gbm::GBTree::ConfigureUpdaters() + 476\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x00000001372c6374 xgboost::gbm::GBTree::Configure(std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>>> const&) + 952\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x00000001372e61b4 xgboost::LearnerConfiguration::Configure() + 1124\n",
      "  [bt] (4) 5   libxgboost.dylib                    0x00000001372e64cc xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 128\n",
      "  [bt] (5) 6   libxgboost.dylib                    0x00000001371ff418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (6) 7   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (7) 8   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (8) 9   _ctypes.cpython-38-darwin.so        0x0000000106057de4 _ctypes_callproc + 1236\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:54] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/gbm/../common/common.h:239: XGBoost version not compiled with GPU support.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x00000001373e5bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x00000001374cb21c xgboost::gbm::GBTree::ConfigureUpdaters() + 476\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x00000001374c6374 xgboost::gbm::GBTree::Configure(std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>>> const&) + 952\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x00000001374e61b4 xgboost::LearnerConfiguration::Configure() + 1124\n",
      "  [bt] (4) 5   libxgboost.dylib                    0x00000001374e64cc xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 128\n",
      "  [bt] (5) 6   libxgboost.dylib                    0x00000001373ff418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (6) 7   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (7) 8   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (8) 9   _ctypes.cpython-38-darwin.so        0x00000001047fbde4 _ctypes_callproc + 1236\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:54] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/objective/regression_obj.cu:148: label must be greater than -1 for rmsle so that log(label + 1) can be valid.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x00000001373e5bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x000000013754c244 xgboost::obj::RegLossObj<xgboost::obj::SquaredLogError>::GetGradient(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, int, xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float>>*) + 580\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x00000001374e66ac xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 608\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x00000001373ff418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (4) 5   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (5) 6   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (6) 7   _ctypes.cpython-38-darwin.so        0x00000001047fbde4 _ctypes_callproc + 1236\n",
      "  [bt] (7) 8   _ctypes.cpython-38-darwin.so        0x00000001047f4d24 PyCFuncPtr_call + 1172\n",
      "  [bt] (8) 9   libpython3.8.dylib                  0x000000010321bfc8 _PyObject_MakeTpCall + 372\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:55] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/gbm/../common/common.h:239: XGBoost version not compiled with GPU support.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x0000000130005bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x00000001300eb21c xgboost::gbm::GBTree::ConfigureUpdaters() + 476\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x00000001300e6374 xgboost::gbm::GBTree::Configure(std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>>> const&) + 952\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x00000001301061b4 xgboost::LearnerConfiguration::Configure() + 1124\n",
      "  [bt] (4) 5   libxgboost.dylib                    0x00000001301064cc xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 128\n",
      "  [bt] (5) 6   libxgboost.dylib                    0x000000013001f418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (6) 7   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (7) 8   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (8) 9   _ctypes.cpython-38-darwin.so        0x00000001010ebde4 _ctypes_callproc + 1236\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:55] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/objective/regression_obj.cu:148: label must be greater than -1 for rmsle so that log(label + 1) can be valid.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x0000000123325bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x000000012348c244 xgboost::obj::RegLossObj<xgboost::obj::SquaredLogError>::GetGradient(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, int, xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float>>*) + 580\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x00000001234266ac xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 608\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x000000012333f418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (4) 5   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (5) 6   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (6) 7   _ctypes.cpython-38-darwin.so        0x000000010595bde4 _ctypes_callproc + 1236\n",
      "  [bt] (7) 8   _ctypes.cpython-38-darwin.so        0x0000000105954d24 PyCFuncPtr_call + 1172\n",
      "  [bt] (8) 9   libpython3.8.dylib                  0x0000000104c87fc8 _PyObject_MakeTpCall + 372\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:55] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/objective/regression_obj.cu:148: label must be greater than -1 for rmsle so that log(label + 1) can be valid.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x000000012d005bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x000000012d16c244 xgboost::obj::RegLossObj<xgboost::obj::SquaredLogError>::GetGradient(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, int, xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float>>*) + 580\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x000000012d1066ac xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 608\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x000000012d01f418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (4) 5   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (5) 6   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (6) 7   _ctypes.cpython-38-darwin.so        0x0000000105987de4 _ctypes_callproc + 1236\n",
      "  [bt] (7) 8   _ctypes.cpython-38-darwin.so        0x0000000105980d24 PyCFuncPtr_call + 1172\n",
      "  [bt] (8) 9   libpython3.8.dylib                  0x0000000104cb3fc8 _PyObject_MakeTpCall + 372\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:56] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/gbm/../common/common.h:239: XGBoost version not compiled with GPU support.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x000000012d005bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x000000012d0eb21c xgboost::gbm::GBTree::ConfigureUpdaters() + 476\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x000000012d0e6374 xgboost::gbm::GBTree::Configure(std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>>> const&) + 952\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x000000012d1061b4 xgboost::LearnerConfiguration::Configure() + 1124\n",
      "  [bt] (4) 5   libxgboost.dylib                    0x000000012d1064cc xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 128\n",
      "  [bt] (5) 6   libxgboost.dylib                    0x000000012d01f418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (6) 7   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (7) 8   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (8) 9   _ctypes.cpython-38-darwin.so        0x0000000105987de4 _ctypes_callproc + 1236\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:55] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/objective/regression_obj.cu:148: label must be greater than -1 for rmsle so that log(label + 1) can be valid.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x0000000128005bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x000000012816c244 xgboost::obj::RegLossObj<xgboost::obj::SquaredLogError>::GetGradient(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, int, xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float>>*) + 580\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x00000001281066ac xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 608\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x000000012801f418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (4) 5   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (5) 6   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (6) 7   _ctypes.cpython-38-darwin.so        0x00000001014f3de4 _ctypes_callproc + 1236\n",
      "  [bt] (7) 8   _ctypes.cpython-38-darwin.so        0x00000001014ecd24 PyCFuncPtr_call + 1172\n",
      "  [bt] (8) 9   libpython3.8.dylib                  0x000000010081ffc8 _PyObject_MakeTpCall + 372\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:55] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/gbm/../common/common.h:239: XGBoost version not compiled with GPU support.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x0000000128005bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x00000001280eb21c xgboost::gbm::GBTree::ConfigureUpdaters() + 476\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x00000001280e6374 xgboost::gbm::GBTree::Configure(std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>>> const&) + 952\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x00000001281061b4 xgboost::LearnerConfiguration::Configure() + 1124\n",
      "  [bt] (4) 5   libxgboost.dylib                    0x00000001281064cc xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 128\n",
      "  [bt] (5) 6   libxgboost.dylib                    0x000000012801f418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (6) 7   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (7) 8   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (8) 9   _ctypes.cpython-38-darwin.so        0x00000001014f3de4 _ctypes_callproc + 1236\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "13 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:55] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/objective/regression_obj.cu:148: label must be greater than -1 for rmsle so that log(label + 1) can be valid.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x00000001373e5bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x000000013754c244 xgboost::obj::RegLossObj<xgboost::obj::SquaredLogError>::GetGradient(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, int, xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float>>*) + 580\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x00000001374e66ac xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 608\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x00000001373ff418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (4) 5   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (5) 6   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (6) 7   _ctypes.cpython-38-darwin.so        0x00000001047fbde4 _ctypes_callproc + 1236\n",
      "  [bt] (7) 8   _ctypes.cpython-38-darwin.so        0x00000001047f4d24 PyCFuncPtr_call + 1172\n",
      "  [bt] (8) 9   libpython3.8.dylib                  0x000000010321bfc8 _PyObject_MakeTpCall + 372\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:55] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/objective/regression_obj.cu:148: label must be greater than -1 for rmsle so that log(label + 1) can be valid.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x0000000130005bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x000000013016c244 xgboost::obj::RegLossObj<xgboost::obj::SquaredLogError>::GetGradient(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, int, xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float>>*) + 580\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x00000001301066ac xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 608\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x000000013001f418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (4) 5   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (5) 6   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (6) 7   _ctypes.cpython-38-darwin.so        0x00000001010ebde4 _ctypes_callproc + 1236\n",
      "  [bt] (7) 8   _ctypes.cpython-38-darwin.so        0x00000001010e4d24 PyCFuncPtr_call + 1172\n",
      "  [bt] (8) 9   libpython3.8.dylib                  0x0000000100417fc8 _PyObject_MakeTpCall + 372\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "19 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:55] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/gbm/../common/common.h:239: XGBoost version not compiled with GPU support.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x000000012dbe5bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x000000012dccb21c xgboost::gbm::GBTree::ConfigureUpdaters() + 476\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x000000012dcc6374 xgboost::gbm::GBTree::Configure(std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>>> const&) + 952\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x000000012dce61b4 xgboost::LearnerConfiguration::Configure() + 1124\n",
      "  [bt] (4) 5   libxgboost.dylib                    0x000000012dce64cc xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 128\n",
      "  [bt] (5) 6   libxgboost.dylib                    0x000000012dbff418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (6) 7   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (7) 8   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (8) 9   _ctypes.cpython-38-darwin.so        0x000000010492fde4 _ctypes_callproc + 1236\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:56] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/objective/regression_obj.cu:148: label must be greater than -1 for rmsle so that log(label + 1) can be valid.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x0000000128005bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x000000012816c244 xgboost::obj::RegLossObj<xgboost::obj::SquaredLogError>::GetGradient(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, int, xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float>>*) + 580\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x00000001281066ac xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 608\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x000000012801f418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (4) 5   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (5) 6   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (6) 7   _ctypes.cpython-38-darwin.so        0x00000001014f3de4 _ctypes_callproc + 1236\n",
      "  [bt] (7) 8   _ctypes.cpython-38-darwin.so        0x00000001014ecd24 PyCFuncPtr_call + 1172\n",
      "  [bt] (8) 9   libpython3.8.dylib                  0x000000010081ffc8 _PyObject_MakeTpCall + 372\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:56] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/objective/regression_obj.cu:148: label must be greater than -1 for rmsle so that log(label + 1) can be valid.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x00000001373e5bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x000000013754c244 xgboost::obj::RegLossObj<xgboost::obj::SquaredLogError>::GetGradient(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, int, xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float>>*) + 580\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x00000001374e66ac xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 608\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x00000001373ff418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (4) 5   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (5) 6   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (6) 7   _ctypes.cpython-38-darwin.so        0x00000001047fbde4 _ctypes_callproc + 1236\n",
      "  [bt] (7) 8   _ctypes.cpython-38-darwin.so        0x00000001047f4d24 PyCFuncPtr_call + 1172\n",
      "  [bt] (8) 9   libpython3.8.dylib                  0x000000010321bfc8 _PyObject_MakeTpCall + 372\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:56] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/objective/regression_obj.cu:148: label must be greater than -1 for rmsle so that log(label + 1) can be valid.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x0000000123325bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x000000012348c244 xgboost::obj::RegLossObj<xgboost::obj::SquaredLogError>::GetGradient(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, int, xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float>>*) + 580\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x00000001234266ac xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 608\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x000000012333f418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (4) 5   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (5) 6   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (6) 7   _ctypes.cpython-38-darwin.so        0x000000010595bde4 _ctypes_callproc + 1236\n",
      "  [bt] (7) 8   _ctypes.cpython-38-darwin.so        0x0000000105954d24 PyCFuncPtr_call + 1172\n",
      "  [bt] (8) 9   libpython3.8.dylib                  0x0000000104c87fc8 _PyObject_MakeTpCall + 372\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:56] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/gbm/../common/common.h:239: XGBoost version not compiled with GPU support.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x0000000123325bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x000000012340b21c xgboost::gbm::GBTree::ConfigureUpdaters() + 476\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x0000000123406374 xgboost::gbm::GBTree::Configure(std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>>> const&) + 952\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x00000001234261b4 xgboost::LearnerConfiguration::Configure() + 1124\n",
      "  [bt] (4) 5   libxgboost.dylib                    0x00000001234264cc xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 128\n",
      "  [bt] (5) 6   libxgboost.dylib                    0x000000012333f418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (6) 7   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (7) 8   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (8) 9   _ctypes.cpython-38-darwin.so        0x000000010595bde4 _ctypes_callproc + 1236\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:55] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/objective/regression_obj.cu:148: label must be greater than -1 for rmsle so that log(label + 1) can be valid.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x0000000122805bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x000000012296c244 xgboost::obj::RegLossObj<xgboost::obj::SquaredLogError>::GetGradient(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, int, xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float>>*) + 580\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x00000001229066ac xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 608\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x000000012281f418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (4) 5   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (5) 6   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (6) 7   _ctypes.cpython-38-darwin.so        0x00000001037fbde4 _ctypes_callproc + 1236\n",
      "  [bt] (7) 8   _ctypes.cpython-38-darwin.so        0x00000001037f4d24 PyCFuncPtr_call + 1172\n",
      "  [bt] (8) 9   libpython3.8.dylib                  0x000000010081bfc8 _PyObject_MakeTpCall + 372\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:56] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/objective/regression_obj.cu:148: label must be greater than -1 for rmsle so that log(label + 1) can be valid.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x0000000122805bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x000000012296c244 xgboost::obj::RegLossObj<xgboost::obj::SquaredLogError>::GetGradient(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, int, xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float>>*) + 580\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x00000001229066ac xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 608\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x000000012281f418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (4) 5   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (5) 6   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (6) 7   _ctypes.cpython-38-darwin.so        0x00000001037fbde4 _ctypes_callproc + 1236\n",
      "  [bt] (7) 8   _ctypes.cpython-38-darwin.so        0x00000001037f4d24 PyCFuncPtr_call + 1172\n",
      "  [bt] (8) 9   libpython3.8.dylib                  0x000000010081bfc8 _PyObject_MakeTpCall + 372\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:56] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/gbm/../common/common.h:239: XGBoost version not compiled with GPU support.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x0000000122805bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x00000001228eb21c xgboost::gbm::GBTree::ConfigureUpdaters() + 476\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x00000001228e6374 xgboost::gbm::GBTree::Configure(std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>>> const&) + 952\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x00000001229061b4 xgboost::LearnerConfiguration::Configure() + 1124\n",
      "  [bt] (4) 5   libxgboost.dylib                    0x00000001229064cc xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 128\n",
      "  [bt] (5) 6   libxgboost.dylib                    0x000000012281f418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (6) 7   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (7) 8   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (8) 9   _ctypes.cpython-38-darwin.so        0x00000001037fbde4 _ctypes_callproc + 1236\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:55] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/gbm/../common/common.h:239: XGBoost version not compiled with GPU support.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x00000001371e5bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x00000001372cb21c xgboost::gbm::GBTree::ConfigureUpdaters() + 476\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x00000001372c6374 xgboost::gbm::GBTree::Configure(std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>>> const&) + 952\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x00000001372e61b4 xgboost::LearnerConfiguration::Configure() + 1124\n",
      "  [bt] (4) 5   libxgboost.dylib                    0x00000001372e64cc xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 128\n",
      "  [bt] (5) 6   libxgboost.dylib                    0x00000001371ff418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (6) 7   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (7) 8   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (8) 9   _ctypes.cpython-38-darwin.so        0x0000000106057de4 _ctypes_callproc + 1236\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:55] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/objective/regression_obj.cu:148: label must be greater than -1 for rmsle so that log(label + 1) can be valid.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x00000001371e5bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x000000013734c244 xgboost::obj::RegLossObj<xgboost::obj::SquaredLogError>::GetGradient(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, int, xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float>>*) + 580\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x00000001372e66ac xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 608\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x00000001371ff418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (4) 5   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (5) 6   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (6) 7   _ctypes.cpython-38-darwin.so        0x0000000106057de4 _ctypes_callproc + 1236\n",
      "  [bt] (7) 8   _ctypes.cpython-38-darwin.so        0x0000000106050d24 PyCFuncPtr_call + 1172\n",
      "  [bt] (8) 9   libpython3.8.dylib                  0x0000000105383fc8 _PyObject_MakeTpCall + 372\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:57] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/gbm/../common/common.h:239: XGBoost version not compiled with GPU support.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x000000012dbe5bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x000000012dccb21c xgboost::gbm::GBTree::ConfigureUpdaters() + 476\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x000000012dcc6374 xgboost::gbm::GBTree::Configure(std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>>> const&) + 952\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x000000012dce61b4 xgboost::LearnerConfiguration::Configure() + 1124\n",
      "  [bt] (4) 5   libxgboost.dylib                    0x000000012dce64cc xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 128\n",
      "  [bt] (5) 6   libxgboost.dylib                    0x000000012dbff418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (6) 7   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (7) 8   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (8) 9   _ctypes.cpython-38-darwin.so        0x000000010492fde4 _ctypes_callproc + 1236\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:56] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/objective/regression_obj.cu:148: label must be greater than -1 for rmsle so that log(label + 1) can be valid.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x00000001371e5bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x000000013734c244 xgboost::obj::RegLossObj<xgboost::obj::SquaredLogError>::GetGradient(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, int, xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float>>*) + 580\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x00000001372e66ac xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 608\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x00000001371ff418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (4) 5   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (5) 6   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (6) 7   _ctypes.cpython-38-darwin.so        0x0000000106057de4 _ctypes_callproc + 1236\n",
      "  [bt] (7) 8   _ctypes.cpython-38-darwin.so        0x0000000106050d24 PyCFuncPtr_call + 1172\n",
      "  [bt] (8) 9   libpython3.8.dylib                  0x0000000105383fc8 _PyObject_MakeTpCall + 372\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:57] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/gbm/../common/common.h:239: XGBoost version not compiled with GPU support.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x0000000123325bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x000000012340b21c xgboost::gbm::GBTree::ConfigureUpdaters() + 476\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x0000000123406374 xgboost::gbm::GBTree::Configure(std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>>> const&) + 952\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x00000001234261b4 xgboost::LearnerConfiguration::Configure() + 1124\n",
      "  [bt] (4) 5   libxgboost.dylib                    0x00000001234264cc xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 128\n",
      "  [bt] (5) 6   libxgboost.dylib                    0x000000012333f418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (6) 7   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (7) 8   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (8) 9   _ctypes.cpython-38-darwin.so        0x000000010595bde4 _ctypes_callproc + 1236\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:56] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/objective/regression_obj.cu:148: label must be greater than -1 for rmsle so that log(label + 1) can be valid.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x0000000130005bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x000000013016c244 xgboost::obj::RegLossObj<xgboost::obj::SquaredLogError>::GetGradient(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, int, xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float>>*) + 580\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x00000001301066ac xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 608\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x000000013001f418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (4) 5   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (5) 6   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (6) 7   _ctypes.cpython-38-darwin.so        0x00000001010ebde4 _ctypes_callproc + 1236\n",
      "  [bt] (7) 8   _ctypes.cpython-38-darwin.so        0x00000001010e4d24 PyCFuncPtr_call + 1172\n",
      "  [bt] (8) 9   libpython3.8.dylib                  0x0000000100417fc8 _PyObject_MakeTpCall + 372\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:57] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/objective/regression_obj.cu:148: label must be greater than -1 for rmsle so that log(label + 1) can be valid.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x0000000130005bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x000000013016c244 xgboost::obj::RegLossObj<xgboost::obj::SquaredLogError>::GetGradient(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, int, xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float>>*) + 580\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x00000001301066ac xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 608\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x000000013001f418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (4) 5   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (5) 6   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (6) 7   _ctypes.cpython-38-darwin.so        0x00000001010ebde4 _ctypes_callproc + 1236\n",
      "  [bt] (7) 8   _ctypes.cpython-38-darwin.so        0x00000001010e4d24 PyCFuncPtr_call + 1172\n",
      "  [bt] (8) 9   libpython3.8.dylib                  0x0000000100417fc8 _PyObject_MakeTpCall + 372\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:57] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/gbm/../common/common.h:239: XGBoost version not compiled with GPU support.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x0000000130005bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x00000001300eb21c xgboost::gbm::GBTree::ConfigureUpdaters() + 476\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x00000001300e6374 xgboost::gbm::GBTree::Configure(std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>>> const&) + 952\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x00000001301061b4 xgboost::LearnerConfiguration::Configure() + 1124\n",
      "  [bt] (4) 5   libxgboost.dylib                    0x00000001301064cc xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 128\n",
      "  [bt] (5) 6   libxgboost.dylib                    0x000000013001f418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (6) 7   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (7) 8   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (8) 9   _ctypes.cpython-38-darwin.so        0x00000001010ebde4 _ctypes_callproc + 1236\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:56] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/gbm/../common/common.h:239: XGBoost version not compiled with GPU support.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x00000001373e5bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x00000001374cb21c xgboost::gbm::GBTree::ConfigureUpdaters() + 476\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x00000001374c6374 xgboost::gbm::GBTree::Configure(std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>>> const&) + 952\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x00000001374e61b4 xgboost::LearnerConfiguration::Configure() + 1124\n",
      "  [bt] (4) 5   libxgboost.dylib                    0x00000001374e64cc xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 128\n",
      "  [bt] (5) 6   libxgboost.dylib                    0x00000001373ff418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (6) 7   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (7) 8   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (8) 9   _ctypes.cpython-38-darwin.so        0x00000001047fbde4 _ctypes_callproc + 1236\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:56] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/gbm/../common/common.h:239: XGBoost version not compiled with GPU support.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x0000000128005bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x00000001280eb21c xgboost::gbm::GBTree::ConfigureUpdaters() + 476\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x00000001280e6374 xgboost::gbm::GBTree::Configure(std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>>> const&) + 952\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x00000001281061b4 xgboost::LearnerConfiguration::Configure() + 1124\n",
      "  [bt] (4) 5   libxgboost.dylib                    0x00000001281064cc xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 128\n",
      "  [bt] (5) 6   libxgboost.dylib                    0x000000012801f418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (6) 7   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (7) 8   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (8) 9   _ctypes.cpython-38-darwin.so        0x00000001014f3de4 _ctypes_callproc + 1236\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:57] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/gbm/../common/common.h:239: XGBoost version not compiled with GPU support.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x00000001373e5bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x00000001374cb21c xgboost::gbm::GBTree::ConfigureUpdaters() + 476\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x00000001374c6374 xgboost::gbm::GBTree::Configure(std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>>> const&) + 952\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x00000001374e61b4 xgboost::LearnerConfiguration::Configure() + 1124\n",
      "  [bt] (4) 5   libxgboost.dylib                    0x00000001374e64cc xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 128\n",
      "  [bt] (5) 6   libxgboost.dylib                    0x00000001373ff418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (6) 7   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (7) 8   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (8) 9   _ctypes.cpython-38-darwin.so        0x00000001047fbde4 _ctypes_callproc + 1236\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:57] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/objective/regression_obj.cu:148: label must be greater than -1 for rmsle so that log(label + 1) can be valid.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x0000000128005bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x000000012816c244 xgboost::obj::RegLossObj<xgboost::obj::SquaredLogError>::GetGradient(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, int, xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float>>*) + 580\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x00000001281066ac xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 608\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x000000012801f418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (4) 5   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (5) 6   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (6) 7   _ctypes.cpython-38-darwin.so        0x00000001014f3de4 _ctypes_callproc + 1236\n",
      "  [bt] (7) 8   _ctypes.cpython-38-darwin.so        0x00000001014ecd24 PyCFuncPtr_call + 1172\n",
      "  [bt] (8) 9   libpython3.8.dylib                  0x000000010081ffc8 _PyObject_MakeTpCall + 372\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:57] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/objective/regression_obj.cu:148: label must be greater than -1 for rmsle so that log(label + 1) can be valid.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x000000012dbe5bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x000000012dd4c244 xgboost::obj::RegLossObj<xgboost::obj::SquaredLogError>::GetGradient(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, int, xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float>>*) + 580\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x000000012dce66ac xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 608\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x000000012dbff418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (4) 5   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (5) 6   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (6) 7   _ctypes.cpython-38-darwin.so        0x000000010492fde4 _ctypes_callproc + 1236\n",
      "  [bt] (7) 8   _ctypes.cpython-38-darwin.so        0x0000000104928d24 PyCFuncPtr_call + 1172\n",
      "  [bt] (8) 9   libpython3.8.dylib                  0x0000000103333fc8 _PyObject_MakeTpCall + 372\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:57] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/objective/regression_obj.cu:148: label must be greater than -1 for rmsle so that log(label + 1) can be valid.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x0000000122805bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x000000012296c244 xgboost::obj::RegLossObj<xgboost::obj::SquaredLogError>::GetGradient(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, int, xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float>>*) + 580\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x00000001229066ac xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 608\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x000000012281f418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (4) 5   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (5) 6   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (6) 7   _ctypes.cpython-38-darwin.so        0x00000001037fbde4 _ctypes_callproc + 1236\n",
      "  [bt] (7) 8   _ctypes.cpython-38-darwin.so        0x00000001037f4d24 PyCFuncPtr_call + 1172\n",
      "  [bt] (8) 9   libpython3.8.dylib                  0x000000010081bfc8 _PyObject_MakeTpCall + 372\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:57] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/gbm/../common/common.h:239: XGBoost version not compiled with GPU support.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x0000000122805bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x00000001228eb21c xgboost::gbm::GBTree::ConfigureUpdaters() + 476\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x00000001228e6374 xgboost::gbm::GBTree::Configure(std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>>> const&) + 952\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x00000001229061b4 xgboost::LearnerConfiguration::Configure() + 1124\n",
      "  [bt] (4) 5   libxgboost.dylib                    0x00000001229064cc xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 128\n",
      "  [bt] (5) 6   libxgboost.dylib                    0x000000012281f418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (6) 7   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (7) 8   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (8) 9   _ctypes.cpython-38-darwin.so        0x00000001037fbde4 _ctypes_callproc + 1236\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "13 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:57] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/objective/regression_obj.cu:148: label must be greater than -1 for rmsle so that log(label + 1) can be valid.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x00000001373e5bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x000000013754c244 xgboost::obj::RegLossObj<xgboost::obj::SquaredLogError>::GetGradient(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, int, xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float>>*) + 580\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x00000001374e66ac xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 608\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x00000001373ff418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (4) 5   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (5) 6   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (6) 7   _ctypes.cpython-38-darwin.so        0x00000001047fbde4 _ctypes_callproc + 1236\n",
      "  [bt] (7) 8   _ctypes.cpython-38-darwin.so        0x00000001047f4d24 PyCFuncPtr_call + 1172\n",
      "  [bt] (8) 9   libpython3.8.dylib                  0x000000010321bfc8 _PyObject_MakeTpCall + 372\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:57] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/objective/regression_obj.cu:148: label must be greater than -1 for rmsle so that log(label + 1) can be valid.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x000000012d005bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x000000012d16c244 xgboost::obj::RegLossObj<xgboost::obj::SquaredLogError>::GetGradient(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, int, xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float>>*) + 580\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x000000012d1066ac xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 608\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x000000012d01f418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (4) 5   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (5) 6   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (6) 7   _ctypes.cpython-38-darwin.so        0x0000000105987de4 _ctypes_callproc + 1236\n",
      "  [bt] (7) 8   _ctypes.cpython-38-darwin.so        0x0000000105980d24 PyCFuncPtr_call + 1172\n",
      "  [bt] (8) 9   libpython3.8.dylib                  0x0000000104cb3fc8 _PyObject_MakeTpCall + 372\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:23:57] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/gbm/../common/common.h:239: XGBoost version not compiled with GPU support.\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x000000012d005bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x000000012d0eb21c xgboost::gbm::GBTree::ConfigureUpdaters() + 476\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x000000012d0e6374 xgboost::gbm::GBTree::Configure(std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>>> const&) + 952\n",
      "  [bt] (3) 4   libxgboost.dylib                    0x000000012d1061b4 xgboost::LearnerConfiguration::Configure() + 1124\n",
      "  [bt] (4) 5   libxgboost.dylib                    0x000000012d1064cc xgboost::LearnerImpl::UpdateOneIter(int, std::__1::shared_ptr<xgboost::DMatrix>) + 128\n",
      "  [bt] (5) 6   libxgboost.dylib                    0x000000012d01f418 XGBoosterUpdateOneIter + 144\n",
      "  [bt] (6) 7   libffi.dylib                        0x00000001a28ff050 ffi_call_SYSV + 80\n",
      "  [bt] (7) 8   libffi.dylib                        0x00000001a2907af8 ffi_call_int + 1208\n",
      "  [bt] (8) 9   _ctypes.cpython-38-darwin.so        0x0000000105987de4 _ctypes_callproc + 1236\n",
      "\n",
      "\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/jeremy/.pyenv/versions/3.8.16/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [-0.24744929         nan         nan         nan         nan         nan\n",
      " -0.17787489 -0.0661173          nan         nan  0.00294458         nan\n",
      "         nan         nan         nan         nan -0.126651           nan\n",
      " -0.08257363 -0.05640718         nan         nan  0.01827138 -0.10075507\n",
      " -0.14916019         nan         nan         nan -0.22565653         nan\n",
      "         nan         nan -0.19281471         nan         nan         nan\n",
      "         nan         nan         nan         nan -0.09526934         nan\n",
      "         nan         nan         nan         nan -0.08003094 -0.04002617\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan -0.17547868         nan         nan         nan -0.16551051\n",
      "         nan -0.32675188         nan         nan -0.03941943         nan\n",
      "         nan         nan -0.14796015         nan -0.04453252  0.10399519\n",
      "         nan  0.03438296         nan         nan  0.13530351         nan\n",
      "         nan -0.19849169         nan -0.03058903         nan -0.04230221\n",
      "         nan         nan -0.03334435         nan  0.00726342 -0.0683219\n",
      "         nan -0.18761974 -0.02708716         nan         nan         nan\n",
      "         nan  0.0275162  -0.16941454         nan         nan         nan\n",
      "         nan         nan         nan -0.11337815 -0.15011743         nan\n",
      "  0.0389585          nan         nan -0.060646   -0.20217936         nan\n",
      " -0.05703095         nan -0.02163163 -0.21603356         nan -0.18902696\n",
      " -0.01944807         nan -0.10236329 -0.06336691         nan         nan\n",
      "         nan         nan         nan         nan -0.05448984         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan -0.21488817 -0.01659826         nan  0.00101576\n",
      "         nan         nan         nan -0.01151008 -0.15378752         nan\n",
      "         nan         nan -0.04206842         nan         nan         nan\n",
      " -0.00916922 -0.13849323         nan         nan         nan         nan\n",
      " -0.21501972 -0.08621278         nan -0.03102026 -0.11141098 -0.15548345\n",
      "  0.00919639         nan -0.01721928         nan -0.0734647          nan\n",
      " -0.16819875         nan         nan         nan         nan -0.04002617\n",
      " -0.09595612 -0.08535802         nan         nan -0.25175362         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan -0.16431577]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tree_method': 'exact',\n",
       " 'objective': 'reg:squarederror',\n",
       " 'n_estimators': 200,\n",
       " 'min_child_weight': 2,\n",
       " 'max_depth': 2,\n",
       " 'gamma': 0,\n",
       " 'eta': 0.2}"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model to be tuned\n",
    "xgb_base = xgb.XGBRegressor(random_state=100)\n",
    "\n",
    "# Create the random search Random Forest\n",
    "xgb_random = RandomizedSearchCV(estimator = xgb_base, param_distributions = xgb_grid, \n",
    "                                n_iter = 200, cv = 3, verbose = 2, \n",
    "                                random_state = 100, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "xgb_random.fit(X_train_temp, y_train_temp)\n",
    "\n",
    "# Get the optimal parameters\n",
    "xgb_random.best_params_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-19 {color: black;background-color: white;}#sk-container-id-19 pre{padding: 0;}#sk-container-id-19 div.sk-toggleable {background-color: white;}#sk-container-id-19 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-19 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-19 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-19 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-19 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-19 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-19 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-19 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-19 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-19 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-19 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-19 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-19 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-19 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-19 div.sk-item {position: relative;z-index: 1;}#sk-container-id-19 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-19 div.sk-item::before, #sk-container-id-19 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-19 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-19 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-19 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-19 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-19 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-19 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-19 div.sk-label-container {text-align: center;}#sk-container-id-19 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-19 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-19\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eta=0.2, eval_metric=None,\n",
       "             feature_types=None, gamma=0, gpu_id=None, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=2,\n",
       "             max_leaves=None, min_child_weight=2, missing=nan,\n",
       "             monotone_constraints=None, n_estimators=200, n_jobs=None,\n",
       "             num_parallel_tree=None, predictor=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" checked><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eta=0.2, eval_metric=None,\n",
       "             feature_types=None, gamma=0, gpu_id=None, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=2,\n",
       "             max_leaves=None, min_child_weight=2, missing=nan,\n",
       "             monotone_constraints=None, n_estimators=200, n_jobs=None,\n",
       "             num_parallel_tree=None, predictor=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eta=0.2, eval_metric=None,\n",
       "             feature_types=None, gamma=0, gpu_id=None, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=2,\n",
       "             max_leaves=None, min_child_weight=2, missing=nan,\n",
       "             monotone_constraints=None, n_estimators=200, n_jobs=None,\n",
       "             num_parallel_tree=None, predictor=None, ...)"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the final Multiple Linear Regression\n",
    "mlr_final = LinearRegression()\n",
    "\n",
    "# Create the final Random Forest\n",
    "rf_final = RandomForestRegressor(n_estimators = 500,\n",
    "                                 min_samples_split = 10,\n",
    "                                 min_impurity_decrease = 0.1,\n",
    "                                 max_features = 'log2',\n",
    "                                 max_depth = 7,\n",
    "                                 criterion = 'friedman_mse',\n",
    "                                 bootstrap = True,\n",
    "                                 random_state = 100)\n",
    "\n",
    "# Create the fnal Extreme Gradient Booster\n",
    "xgb_final = xgb.XGBRegressor(tree_method = 'exact',\n",
    "                         objective = 'reg:squarederror',\n",
    "                         n_estimators = 200,\n",
    "                         min_child_weight = 2,\n",
    "                         max_depth = 2,\n",
    "                         gamma = 0,\n",
    "                         eta = 0.2,\n",
    "                         random_state = 100)\n",
    "\n",
    "# Train the models using 80% of the original data\n",
    "mlr_final.fit(X_train_temp, y_train_temp)\n",
    "rf_final.fit(X_train_temp, y_train_temp)\n",
    "xgb_final.fit(X_train_temp, y_train_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that compares all final models\n",
    "def final_comparison(models, test_features, test_labels):\n",
    "    scores = pd.DataFrame()\n",
    "    for model in models:\n",
    "        predictions = model.predict(test_features)\n",
    "        mae = round(mean_absolute_error(test_labels, predictions), 4)\n",
    "        mse = round(mean_squared_error(test_labels, predictions), 4)\n",
    "        r2 = round(r2_score(test_labels, predictions), 4)\n",
    "        scores[str(model)] = [mae, mse, r2]\n",
    "    scores.index = ['Mean Absolute Error', 'Mean Squared Error', 'R^2']\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Multivariate Linear Regression</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Extreme Gradient Boosting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <td>0.7404</td>\n",
       "      <td>0.6926</td>\n",
       "      <td>0.7441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <td>0.8645</td>\n",
       "      <td>0.8058</td>\n",
       "      <td>0.9445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R^2</th>\n",
       "      <td>0.1717</td>\n",
       "      <td>0.2279</td>\n",
       "      <td>0.0950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Multivariate Linear Regression  Random Forest  \\\n",
       "Mean Absolute Error                          0.7404         0.6926   \n",
       "Mean Squared Error                           0.8645         0.8058   \n",
       "R^2                                          0.1717         0.2279   \n",
       "\n",
       "                     Extreme Gradient Boosting  \n",
       "Mean Absolute Error                     0.7441  \n",
       "Mean Squared Error                      0.9445  \n",
       "R^2                                     0.0950  "
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the comparison function with the three final models\n",
    "final_scores = final_comparison([mlr_final, rf_final, xgb_final], X_test, y_test)\n",
    "\n",
    "# Adjust the column headers\n",
    "final_scores.columns  = ['Multivariate Linear Regression', 'Random Forest', 'Extreme Gradient Boosting']\n",
    "\n",
    "final_scores.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
